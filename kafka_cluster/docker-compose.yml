version: '2'

services:
  zookeeper:
    image: wurstmeister/zookeeper:latest
    ports:
      - "2181:2181"
    networks:
      - spark_cluster_default

  kafka:
    container_name: kafka_broker
    image: wurstmeister/kafka:latest
    ports:
      - "9092:9092"
    expose:
      - "9093"
    networks:
      - spark_cluster_default
    environment:
      KAFKA_ADVERTISED_LISTENERS: INSIDE://kafka:9093,OUTSIDE://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
      KAFKA_LISTENERS: INSIDE://0.0.0.0:9093,OUTSIDE://0.0.0.0:9092
      KAFKA_INTER_BROKER_LISTENER_NAME: INSIDE
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_CREATE_TOPICS: "my-topic:1:1"
      KAFKA_LOG_RETENTION_MS: 7200000  # Retain logs for 72 hours (in milliseconds)
      KAFKA_LOG_RETENTION_BYTES: 1073741824  # Retain logs up to 1GB
      KAFKA_LOG_SEGMENT_BYTES: 1073741824  # Log segment size: 1GB
      KAFKA_LOG_CLEANUP_POLICY: delete
    volumes:
      - /mnt/d/Eigene_Dokumente/Uni/Master/Mexiko/Big_Data/kafka_data:/var/lib/kafka/data
      - /var/run/docker.sock:/var/run/docker.sock

networks:
  spark_cluster_default:
    name: spark_cluster_default
    external: true