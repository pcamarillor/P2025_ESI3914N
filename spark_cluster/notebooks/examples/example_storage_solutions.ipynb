{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> <img src=\"../labs/img/ITESOLogo.png\" alt=\"ITESO\" width=\"480\" height=\"130\"> </center>\n",
    "# <center> **Departamento de Electrónica, Sistemas e Informática** </center>\n",
    "---\n",
    "## <center> **Big Data** </center>\n",
    "---\n",
    "### <center> **Spring 2025** </center>\n",
    "---\n",
    "### <center> **Examples on storage solutions for Big Data (files)** </center>\n",
    "---\n",
    "**Profesor**: Dr. Pablo Camarillo Ramirez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creacion de la conexión con el cluster de spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/11 00:41:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/03/11 00:41:10 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SparkSQL-Storage-Solutions\") \\\n",
    "    .master(\"spark://078b2e28e517:7077\") \\\n",
    "    .config(\"spark.ui.port\",\"4040\") \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Car rental service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- agency_id: string (nullable = true)\n",
      " |-- agency_info: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/11 00:41:26 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "25/03/11 00:41:41 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------------------------------------------+\n",
      "|agency_id|agency_info                                          |\n",
      "+---------+-----------------------------------------------------+\n",
      "|1        |{'agency_name': 'NYC Rentals', 'city': 'New York'}   |\n",
      "|2        |{'agency_name': 'LA Car Rental', 'city': 'Londres'}  |\n",
      "|3        |{'agency_name': 'Zapopan Auto', 'city': 'Zapopan'}   |\n",
      "|4        |{'agency_name': 'SF Cars', 'city': 'San Francisco'}  |\n",
      "|5        |{'agency_name': 'Mexico Cars', 'city': 'Mexico City'}|\n",
      "+---------+-----------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from team_name.spark_utils import SparkUtils\n",
    "agencies_schema = SparkUtils.generate_schema([(\"agency_id\", \"string\"), (\"agency_info\", \"string\")])\n",
    "\n",
    "agencies_df = spark.read \\\n",
    "                .schema(agencies_schema) \\\n",
    "                .option(\"header\", \"true\") \\\n",
    "                .csv(\"/home/jovyan/notebooks/data/rentals_dataset/agencies.csv\")\n",
    "\n",
    "agencies_df.printSchema()\n",
    "\n",
    "agencies_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------------------------------------------+-------------+\n",
      "|agency_id|agency_info                                          |agency_name  |\n",
      "+---------+-----------------------------------------------------+-------------+\n",
      "|1        |{'agency_name': 'NYC Rentals', 'city': 'New York'}   |NYC Rentals  |\n",
      "|2        |{'agency_name': 'LA Car Rental', 'city': 'Londres'}  |LA Car Rental|\n",
      "|3        |{'agency_name': 'Zapopan Auto', 'city': 'Zapopan'}   |Zapopan Auto |\n",
      "|4        |{'agency_name': 'SF Cars', 'city': 'San Francisco'}  |SF Cars      |\n",
      "|5        |{'agency_name': 'Mexico Cars', 'city': 'Mexico City'}|Mexico Cars  |\n",
      "+---------+-----------------------------------------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import get_json_object\n",
    "agencies_df = agencies_df.withColumn(\"agency_name\", get_json_object(agencies_df.agency_info, \"$.agency_name\"))\n",
    "agencies_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- brand_id: integer (nullable = true)\n",
      " |-- brand_info: string (nullable = true)\n",
      "\n",
      "+--------+------------------------------------------------------+-------------+\n",
      "|brand_id|brand_info                                            |brand_name   |\n",
      "+--------+------------------------------------------------------+-------------+\n",
      "|1       |{'brand_name': 'Mercedes-Benz', 'country': 'Tanzania'}|Mercedes-Benz|\n",
      "|2       |{'brand_name': 'BMW', 'country': 'Hungary'}           |BMW          |\n",
      "|3       |{'brand_name': 'Audi', 'country': 'Senegal'}          |Audi         |\n",
      "|4       |{'brand_name': 'Ford', 'country': 'Tuvalu'}           |Ford         |\n",
      "|5       |{'brand_name': 'BYD', 'country': 'Italy'}             |BYD          |\n",
      "+--------+------------------------------------------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "brands_schema = SparkUtils.generate_schema([(\"brand_id\", \"integer\"), (\"brand_info\", \"string\")])\n",
    "brands_df = spark.read.option(\"header\", \"true\").schema(brands_schema).csv(\"/home/jovyan/notebooks/data/rentals_dataset/brands.csv\")\n",
    "brands_df.printSchema()\n",
    "brands_df = brands_df.withColumn(\"brand_name\", get_json_object(brands_df.brand_info, \"$.brand_name\"))\n",
    "brands_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- car_id: integer (nullable = true)\n",
      " |-- car_info: string (nullable = true)\n",
      "\n",
      "+------+-------------------------------------------------------------------------------------+---------------------------------+--------+\n",
      "|car_id|car_info                                                                             |car_name                         |brand_id|\n",
      "+------+-------------------------------------------------------------------------------------+---------------------------------+--------+\n",
      "|1     |{'car_name': 'Tucker, Hull and Gallegos Model 1', 'brand_id': 5, 'price_per_day': 68}|Tucker, Hull and Gallegos Model 1|5       |\n",
      "|2     |{'car_name': 'Howard-Snow Model 7', 'brand_id': 5, 'price_per_day': 55}              |Howard-Snow Model 7              |5       |\n",
      "|3     |{'car_name': 'Wagner LLC Model 2', 'brand_id': 2, 'price_per_day': 194}              |Wagner LLC Model 2               |2       |\n",
      "|4     |{'car_name': 'Campos PLC Model 8', 'brand_id': 1, 'price_per_day': 107}              |Campos PLC Model 8               |1       |\n",
      "|5     |{'car_name': 'Archer-Patel Model 3', 'brand_id': 4, 'price_per_day': 136}            |Archer-Patel Model 3             |4       |\n",
      "+------+-------------------------------------------------------------------------------------+---------------------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cars_schema = SparkUtils.generate_schema([(\"car_id\", \"integer\"), (\"car_info\", \"string\")])\n",
    "cars_df = spark.read.option(\"header\", \"true\").schema(cars_schema).csv(\"/home/jovyan/notebooks/data/rentals_dataset/cars.csv\")\n",
    "cars_df.printSchema()\n",
    "cars_df = cars_df.withColumn(\"car_name\", get_json_object(cars_df.car_info, \"$.car_name\")) \\\n",
    "                .withColumn(\"brand_id\", get_json_object(cars_df.car_info, \"$.brand_id\")) \n",
    "cars_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- customer_id: integer (nullable = true)\n",
      " |-- customer_info: string (nullable = true)\n",
      "\n",
      "+-----------+--------------------+-------------------+\n",
      "|customer_id|       customer_info|      customer_name|\n",
      "+-----------+--------------------+-------------------+\n",
      "|          1|{'customer_name':...|  Martin Graves DVM|\n",
      "|          2|{'customer_name':...|   Frederick Wilson|\n",
      "|          3|{'customer_name':...|       Gabriela Lee|\n",
      "|          4|{'customer_name':...|     Devin Thornton|\n",
      "|          5|{'customer_name':...|Christopher Simmons|\n",
      "+-----------+--------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customers_schema = SparkUtils.generate_schema([(\"customer_id\", \"integer\"), (\"customer_info\", \"string\")])\n",
    "customers_df = spark.read.option(\"header\", \"true\").schema(customers_schema).csv(\"/home/jovyan/notebooks/data/rentals_dataset/customers.csv\")\n",
    "customers_df.printSchema()\n",
    "customers_df = customers_df.withColumn(\"customer_name\", get_json_object(customers_df.customer_info, \"$.customer_name\"))\n",
    "customers_df.show(5, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- rental_id: integer (nullable = true)\n",
      " |-- rental_info: string (nullable = true)\n",
      "\n",
      "+---------+--------------------------------------------------+\n",
      "|rental_id|rental_info                                       |\n",
      "+---------+--------------------------------------------------+\n",
      "|12740    |{'car_id': 23, 'customer_id': 42, 'agency_id': 1} |\n",
      "|12741    |{'car_id': 19, 'customer_id': 146, 'agency_id': 2}|\n",
      "|12742    |{'car_id': 24, 'customer_id': 143, 'agency_id': 3}|\n",
      "|12743    |{'car_id': 22, 'customer_id': 90, 'agency_id': 4} |\n",
      "|12744    |{'car_id': 9, 'customer_id': 115, 'agency_id': 3} |\n",
      "+---------+--------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rental_cars_schema = SparkUtils.generate_schema([(\"rental_id\", \"integer\"), (\"rental_info\", \"string\")])\n",
    "rental_cars_df = spark.read.option(\"header\", \"true\").schema(rental_cars_schema).csv(\"/home/jovyan/notebooks/data/rentals_dataset/rentals/\")\n",
    "rental_cars_df.printSchema()\n",
    "rental_cars_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------------------------------------+------+-----------+---------+\n",
      "|rental_id|rental_info                                       |car_id|customer_id|agency_id|\n",
      "+---------+--------------------------------------------------+------+-----------+---------+\n",
      "|12740    |{'car_id': 23, 'customer_id': 42, 'agency_id': 1} |23    |42         |1        |\n",
      "|12741    |{'car_id': 19, 'customer_id': 146, 'agency_id': 2}|19    |146        |2        |\n",
      "|12742    |{'car_id': 24, 'customer_id': 143, 'agency_id': 3}|24    |143        |3        |\n",
      "|12743    |{'car_id': 22, 'customer_id': 90, 'agency_id': 4} |22    |90         |4        |\n",
      "|12744    |{'car_id': 9, 'customer_id': 115, 'agency_id': 3} |9     |115        |3        |\n",
      "+---------+--------------------------------------------------+------+-----------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rental_cars_df = rental_cars_df.withColumn(\"car_id\", get_json_object(rental_cars_df.rental_info, '$.car_id')) \\\n",
    "                            .withColumn(\"customer_id\", get_json_object(rental_cars_df.rental_info, '$.customer_id')) \\\n",
    "                            .withColumn(\"agency_id\", get_json_object(rental_cars_df.rental_info, '$.agency_id'))\n",
    "\n",
    "rental_cars_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------------------------------------+------+-----------+---------+------+-----------------------------------------------------------------------------------+-------------------------------+--------+---------+---------------------------------------------------+-------------+-----------+------------------------------------------------------------------------+---------------+\n",
      "|rental_id|rental_info                                       |car_id|customer_id|agency_id|car_id|car_info                                                                           |car_name                       |brand_id|agency_id|agency_info                                        |agency_name  |customer_id|customer_info                                                           |customer_name  |\n",
      "+---------+--------------------------------------------------+------+-----------+---------+------+-----------------------------------------------------------------------------------+-------------------------------+--------+---------+---------------------------------------------------+-------------+-----------+------------------------------------------------------------------------+---------------+\n",
      "|12740    |{'car_id': 23, 'customer_id': 42, 'agency_id': 1} |23    |42         |1        |23    |{'car_name': 'Salazar Ltd Model 6', 'brand_id': 6, 'price_per_day': 163}           |Salazar Ltd Model 6            |6       |1        |{'agency_name': 'NYC Rentals', 'city': 'New York'} |NYC Rentals  |42         |{'customer_name': 'Sara Anderson', 'city': 'Monterrey', 'age': 30}      |Sara Anderson  |\n",
      "|12741    |{'car_id': 19, 'customer_id': 146, 'agency_id': 2}|19    |146        |2        |19    |{'car_name': 'Harris, Lloyd and Payne Model 4', 'brand_id': 2, 'price_per_day': 91}|Harris, Lloyd and Payne Model 4|2       |2        |{'agency_name': 'LA Car Rental', 'city': 'Londres'}|LA Car Rental|146        |{'customer_name': 'Calvin Walker', 'city': 'Mexico City', 'age': 29}    |Calvin Walker  |\n",
      "|12742    |{'car_id': 24, 'customer_id': 143, 'agency_id': 3}|24    |143        |3        |24    |{'car_name': 'Alvarez-Davis Model 6', 'brand_id': 7, 'price_per_day': 104}         |Alvarez-Davis Model 6          |7       |3        |{'agency_name': 'Zapopan Auto', 'city': 'Zapopan'} |Zapopan Auto |143        |{'customer_name': 'Shawn Tran', 'city': 'Monterrey', 'age': 24}         |Shawn Tran     |\n",
      "|12743    |{'car_id': 22, 'customer_id': 90, 'agency_id': 4} |22    |90         |4        |22    |{'car_name': 'Lopez and Sons Model 3', 'brand_id': 2, 'price_per_day': 141}        |Lopez and Sons Model 3         |2       |4        |{'agency_name': 'SF Cars', 'city': 'San Francisco'}|SF Cars      |90         |{'customer_name': 'Edward Mccarthy', 'city': 'San Francisco', 'age': 48}|Edward Mccarthy|\n",
      "|12744    |{'car_id': 9, 'customer_id': 115, 'agency_id': 3} |9     |115        |3        |9     |{'car_name': 'Levy Group Model 8', 'brand_id': 1, 'price_per_day': 57}             |Levy Group Model 8             |1       |3        |{'agency_name': 'Zapopan Auto', 'city': 'Zapopan'} |Zapopan Auto |115        |{'customer_name': 'Antonio Haynes', 'city': 'Mexico City', 'age': 25}   |Antonio Haynes |\n",
      "+---------+--------------------------------------------------+------+-----------+---------+------+-----------------------------------------------------------------------------------+-------------------------------+--------+---------+---------------------------------------------------+-------------+-----------+------------------------------------------------------------------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rental_cars_df = rental_cars_df.join(cars_df, rental_cars_df.car_id == cars_df.car_id, \"inner\") \\\n",
    "                                .join(agencies_df, rental_cars_df.agency_id == agencies_df.agency_id, \"inner\") \\\n",
    "                                .join(customers_df, rental_cars_df.customer_id == customers_df.customer_id, \"inner\")\n",
    "\n",
    "rental_cars_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final result\n",
    "rental_cars_df = rental_cars_df.select(\"rental_id\", \"car_name\", \"agency_name\", \"customer_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------------------+-------------+---------------+\n",
      "|rental_id|car_name                       |agency_name  |customer_name  |\n",
      "+---------+-------------------------------+-------------+---------------+\n",
      "|12740    |Salazar Ltd Model 6            |NYC Rentals  |Sara Anderson  |\n",
      "|12741    |Harris, Lloyd and Payne Model 4|LA Car Rental|Calvin Walker  |\n",
      "|12742    |Alvarez-Davis Model 6          |Zapopan Auto |Shawn Tran     |\n",
      "|12743    |Lopez and Sons Model 3         |SF Cars      |Edward Mccarthy|\n",
      "|12744    |Levy Group Model 8             |Zapopan Auto |Antonio Haynes |\n",
      "+---------+-------------------------------+-------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rental_cars_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rental_cars_df.createOrReplaceTempView(\"rentals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------+\n",
      "|rental_id|  customer_name|\n",
      "+---------+---------------+\n",
      "|    12740|  Sara Anderson|\n",
      "|    12741|  Calvin Walker|\n",
      "|    12742|     Shawn Tran|\n",
      "|    12743|Edward Mccarthy|\n",
      "|    12744| Antonio Haynes|\n",
      "+---------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT rental_id, customer_name FROM rentals\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+\n",
      "|  agency_name|rentals_count|\n",
      "+-------------+-------------+\n",
      "| Zapopan Auto|         4425|\n",
      "|LA Car Rental|         4451|\n",
      "|      SF Cars|         4481|\n",
      "|  NYC Rentals|         4477|\n",
      "+-------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT agency_name, count(*) as rentals_count FROM rentals GROUP BY agency_name\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Register temporal views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "agencies_df.createOrReplaceTempView(\"agencies\")\n",
    "brands_df.createOrReplaceTempView(\"brands\")\n",
    "customers_df.createOrReplaceTempView(\"customers\")\n",
    "rental_cars_df.createOrReplaceTempView(\"rentals\")\n",
    "cars_df.createOrReplaceTempView(\"cars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify the most popular car brands by the number of rentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+-------------+\n",
      "|car_id|            car_name|   brand_name|\n",
      "+------+--------------------+-------------+\n",
      "|     1|Tucker, Hull and ...|          BYD|\n",
      "|     2| Howard-Snow Model 7|          BYD|\n",
      "|     3|  Wagner LLC Model 2|          BMW|\n",
      "|     4|  Campos PLC Model 8|Mercedes-Benz|\n",
      "|     5|Archer-Patel Model 3|         Ford|\n",
      "+------+--------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Re create cars view\n",
    "cars_df = spark.read.option(\"header\", \"true\").schema(cars_schema).csv(\"/home/jovyan/notebooks/data/rentals_dataset/cars.csv\")\n",
    "cars_df.createOrReplaceTempView(\"cars\")\n",
    "cars_df = spark.sql(\"\"\"\n",
    "                    SELECT c.car_id, \n",
    "                           get_json_object(c.car_info, '$.car_name') AS car_name,\n",
    "                           get_json_object(b.brand_info, '$.brand_name') AS brand_name\n",
    "                    FROM cars c \n",
    "                    JOIN brands b\n",
    "                    ON get_json_object(c.car_info, '$.brand_id') = b.brand_id\n",
    "                    \"\"\")\n",
    "cars_df.createOrReplaceTempView(\"cars\")\n",
    "spark.sql(\"SELECT * FROM cars\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+\n",
      "|brand_name|rental_count|\n",
      "+----------+------------+\n",
      "|       BMW|        5471|\n",
      "|     Honda|        4258|\n",
      "|      Ford|        2473|\n",
      "+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Re create rentals view\n",
    "rental_cars_df = spark.read.option(\"header\", \"true\").schema(rental_cars_schema).csv(\"/home/jovyan/notebooks/data/rentals_dataset/rentals/\")\n",
    "rental_cars_df.createOrReplaceTempView(\"rentals\")\n",
    "rental_cars_df = spark.sql(\"\"\"\n",
    "            SELECT r.rental_id,\n",
    "                   c.car_name,\n",
    "                   c.brand_name,\n",
    "                   a.agency_name,\n",
    "                   cus.customer_name\n",
    "            FROM rentals r\n",
    "            JOIN cars c ON get_json_object(r.rental_info, '$.car_id') = c.car_id\n",
    "            JOIN agencies a ON get_json_object(r.rental_info, '$.agency_id') = a.agency_id\n",
    "            JOIN customers cus ON get_json_object(r.rental_info, '$.customer_id') = cus.customer_id\n",
    "          \"\"\")\n",
    "rental_cars_df.createOrReplaceTempView(\"rentals\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "          SELECT brand_name, count(*) AS rental_count FROM rentals \n",
    "          GROUP BY brand_name ORDER BY rental_count DESC LIMIT 3\n",
    "          \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the top 5 customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------+\n",
      "|    customer_name|rental_count|\n",
      "+-----------------+------------+\n",
      "|Catherine Alvarez|         136|\n",
      "|    Travis Butler|         133|\n",
      "|     Corey Wilson|         132|\n",
      "|      Ronald Hall|         131|\n",
      "|    Cynthia White|         131|\n",
      "+-----------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "            SELECT customer_name, count(*) AS rental_count FROM rentals GROUP BY customer_name ORDER BY rental_count DESC LIMIT 5\n",
    "          \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find which car generate the most revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|            car_name|rental_count|\n",
      "+--------------------+------------+\n",
      "|Bryan, Barnes and...|         654|\n",
      "|Clayton-Cook Mode...|         653|\n",
      "|Summers, Barnett ...|         653|\n",
      "|Harris, Lloyd and...|         649|\n",
      "|Myers, Thornton a...|         643|\n",
      "+--------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT car_name, count(*) AS rental_count FROM rentals GROUP BY car_name ORDER BY rental_count DESC LIMIT 5\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Persist data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "rental_cars_df.write \\\n",
    "                .mode(\"overwrite\") \\\n",
    "                .partitionBy(\"agency_name\") \\\n",
    "                .parquet(\"/home/jovyan/notebooks/data/rentals_output/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32K\tnotebooks/data/rentals_output/agency_name=Zapopan Auto\n",
      "32K\tnotebooks/data/rentals_output/agency_name=NYC Rentals\n",
      "32K\tnotebooks/data/rentals_output/agency_name=SF Cars\n",
      "32K\tnotebooks/data/rentals_output/agency_name=LA Car Rental\n",
      "132K\tnotebooks/data/rentals_output/\n"
     ]
    }
   ],
   "source": [
    "!du -h notebooks/data/rentals_output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/11 02:16:22 ERROR TaskSchedulerImpl: Lost executor 1 on 172.24.0.5: worker lost: Not receiving heartbeat for 60 seconds\n",
      "25/03/11 02:16:22 ERROR TaskSchedulerImpl: Lost executor 0 on 172.24.0.4: worker lost: Not receiving heartbeat for 60 seconds\n",
      "25/03/11 02:57:10 WARN HeartbeatReceiver: Removing executor 3 with no recent heartbeats: 2428841 ms exceeds timeout 120000 ms\n",
      "25/03/11 02:57:10 ERROR TaskSchedulerImpl: Lost executor 3 on 172.24.0.5: Executor heartbeat timed out after 2428841 ms\n",
      "25/03/11 03:23:29 ERROR TaskSchedulerImpl: Lost executor 4 on 172.24.0.5: worker lost: Not receiving heartbeat for 60 seconds\n",
      "25/03/11 03:23:29 ERROR TaskSchedulerImpl: Lost executor 2 on 172.24.0.4: worker lost: Not receiving heartbeat for 60 seconds\n",
      "25/03/11 03:40:44 WARN HeartbeatReceiver: Removing executor 5 with no recent heartbeats: 952764 ms exceeds timeout 120000 ms\n",
      "25/03/11 03:40:44 WARN HeartbeatReceiver: Removing executor 6 with no recent heartbeats: 956211 ms exceeds timeout 120000 ms\n",
      "25/03/11 03:40:44 ERROR TaskSchedulerImpl: Lost executor 5 on 172.24.0.5: Executor heartbeat timed out after 952764 ms\n",
      "25/03/11 03:40:44 ERROR TaskSchedulerImpl: Lost executor 6 on 172.24.0.4: Executor heartbeat timed out after 956211 ms\n",
      "25/03/11 03:43:59 ERROR TaskSchedulerImpl: Lost executor 8 on 172.24.0.4: worker lost: Not receiving heartbeat for 60 seconds\n",
      "25/03/11 03:43:59 ERROR TaskSchedulerImpl: Lost executor 7 on 172.24.0.5: worker lost: Not receiving heartbeat for 60 seconds\n",
      "25/03/11 03:55:17 ERROR TaskSchedulerImpl: Lost executor 10 on 172.24.0.5: worker lost: Not receiving heartbeat for 60 seconds\n",
      "25/03/11 03:55:17 ERROR TaskSchedulerImpl: Lost executor 9 on 172.24.0.4: worker lost: Not receiving heartbeat for 60 seconds\n",
      "25/03/11 04:01:59 ERROR TaskSchedulerImpl: Lost executor 12 on 172.24.0.5: worker lost: Not receiving heartbeat for 60 seconds\n",
      "25/03/11 04:01:59 ERROR TaskSchedulerImpl: Lost executor 11 on 172.24.0.4: worker lost: Not receiving heartbeat for 60 seconds\n",
      "25/03/11 04:15:53 WARN HeartbeatReceiver: Removing executor 14 with no recent heartbeats: 817425 ms exceeds timeout 120000 ms\n",
      "25/03/11 04:15:53 ERROR TaskSchedulerImpl: Lost executor 14 on 172.24.0.4: Executor heartbeat timed out after 817425 ms\n",
      "25/03/11 04:42:07 ERROR TaskSchedulerImpl: Lost executor 15 on 172.24.0.4: worker lost: Not receiving heartbeat for 60 seconds\n",
      "25/03/11 04:42:07 ERROR TaskSchedulerImpl: Lost executor 13 on 172.24.0.5: worker lost: Not receiving heartbeat for 60 seconds\n",
      "25/03/11 04:46:14 WARN HeartbeatReceiver: Removing executor 16 with no recent heartbeats: 225987 ms exceeds timeout 120000 ms\n",
      "25/03/11 04:46:14 WARN HeartbeatReceiver: Removing executor 17 with no recent heartbeats: 227103 ms exceeds timeout 120000 ms\n",
      "25/03/11 04:46:14 ERROR TaskSchedulerImpl: Lost executor 16 on 172.24.0.5: Executor heartbeat timed out after 225987 ms\n",
      "25/03/11 04:46:14 ERROR TaskSchedulerImpl: Lost executor 17 on 172.24.0.4: Executor heartbeat timed out after 227103 ms\n",
      "25/03/11 04:48:47 ERROR TaskSchedulerImpl: Lost executor 18 on 172.24.0.5: worker lost: Not receiving heartbeat for 60 seconds\n",
      "25/03/11 04:48:47 ERROR TaskSchedulerImpl: Lost executor 19 on 172.24.0.4: worker lost: Not receiving heartbeat for 60 seconds\n",
      "25/03/11 04:55:00 WARN HeartbeatReceiver: Removing executor 20 with no recent heartbeats: 355116 ms exceeds timeout 120000 ms\n",
      "25/03/11 04:55:00 WARN HeartbeatReceiver: Removing executor 21 with no recent heartbeats: 350479 ms exceeds timeout 120000 ms\n",
      "25/03/11 04:55:00 ERROR TaskSchedulerImpl: Lost executor 20 on 172.24.0.5: Executor heartbeat timed out after 355116 ms\n",
      "25/03/11 04:55:00 ERROR TaskSchedulerImpl: Lost executor 21 on 172.24.0.4: Executor heartbeat timed out after 350479 ms\n",
      "25/03/11 05:00:29 ERROR TaskSchedulerImpl: Lost executor 23 on 172.24.0.4: worker lost: Not receiving heartbeat for 60 seconds\n",
      "25/03/11 05:00:29 ERROR TaskSchedulerImpl: Lost executor 22 on 172.24.0.5: worker lost: Not receiving heartbeat for 60 seconds\n",
      "25/03/11 05:34:21 ERROR TaskSchedulerImpl: Lost executor 24 on 172.24.0.5: worker lost: Not receiving heartbeat for 60 seconds\n",
      "25/03/11 05:34:21 ERROR TaskSchedulerImpl: Lost executor 25 on 172.24.0.4: worker lost: Not receiving heartbeat for 60 seconds\n",
      "25/03/11 06:01:23 WARN HeartbeatReceiver: Removing executor 26 with no recent heartbeats: 1480356 ms exceeds timeout 120000 ms\n",
      "25/03/11 06:01:23 ERROR TaskSchedulerImpl: Lost executor 26 on 172.24.0.5: Executor heartbeat timed out after 1480356 ms\n",
      "25/03/11 06:19:17 ERROR TaskSchedulerImpl: Lost executor 28 on 172.24.0.5: worker lost: Not receiving heartbeat for 60 seconds\n",
      "25/03/11 06:19:17 ERROR TaskSchedulerImpl: Lost executor 27 on 172.24.0.4: worker lost: Not receiving heartbeat for 60 seconds\n",
      "25/03/11 06:37:40 WARN HeartbeatReceiver: Removing executor 29 with no recent heartbeats: 1080639 ms exceeds timeout 120000 ms\n",
      "25/03/11 06:37:40 ERROR TaskSchedulerImpl: Lost executor 29 on 172.24.0.5: Executor heartbeat timed out after 1080639 ms\n",
      "25/03/11 06:54:12 WARN HeartbeatReceiver: Removing executor 31 with no recent heartbeats: 941617 ms exceeds timeout 120000 ms\n",
      "25/03/11 06:54:12 ERROR TaskSchedulerImpl: Lost executor 31 on 172.24.0.5: Executor heartbeat timed out after 941617 ms\n",
      "25/03/11 07:26:16 ERROR TaskSchedulerImpl: Lost executor 32 on 172.24.0.5: worker lost: Not receiving heartbeat for 60 seconds\n",
      "25/03/11 07:26:16 ERROR TaskSchedulerImpl: Lost executor 30 on 172.24.0.4: worker lost: Not receiving heartbeat for 60 seconds\n",
      "25/03/11 07:41:26 WARN HeartbeatReceiver: Removing executor 33 with no recent heartbeats: 888568 ms exceeds timeout 120000 ms\n",
      "25/03/11 07:41:26 WARN HeartbeatReceiver: Removing executor 34 with no recent heartbeats: 889242 ms exceeds timeout 120000 ms\n",
      "25/03/11 07:41:26 ERROR TaskSchedulerImpl: Lost executor 33 on 172.24.0.5: Executor heartbeat timed out after 888568 ms\n",
      "25/03/11 07:41:26 ERROR TaskSchedulerImpl: Lost executor 34 on 172.24.0.4: Executor heartbeat timed out after 889242 ms\n",
      "25/03/11 08:14:55 WARN HeartbeatReceiver: Removing executor 35 with no recent heartbeats: 1957333 ms exceeds timeout 120000 ms\n",
      "25/03/11 08:14:55 ERROR TaskSchedulerImpl: Lost executor 35 on 172.24.0.5: Executor heartbeat timed out after 1957333 ms\n",
      "25/03/11 08:49:11 ERROR TaskSchedulerImpl: Lost executor 37 on 172.24.0.5: worker lost: Not receiving heartbeat for 60 seconds\n",
      "25/03/11 08:49:11 ERROR TaskSchedulerImpl: Lost executor 36 on 172.24.0.4: worker lost: Not receiving heartbeat for 60 seconds\n",
      "25/03/11 09:31:17 WARN HeartbeatReceiver: Removing executor 38 with no recent heartbeats: 2446019 ms exceeds timeout 120000 ms\n",
      "25/03/11 09:31:17 WARN HeartbeatReceiver: Removing executor 39 with no recent heartbeats: 2448584 ms exceeds timeout 120000 ms\n",
      "25/03/11 09:31:17 ERROR TaskSchedulerImpl: Lost executor 38 on 172.24.0.5: Executor heartbeat timed out after 2446019 ms\n",
      "25/03/11 09:31:17 ERROR TaskSchedulerImpl: Lost executor 39 on 172.24.0.4: Executor heartbeat timed out after 2448584 ms\n",
      "25/03/11 09:52:47 ERROR TaskSchedulerImpl: Lost executor 40 on 172.24.0.5: worker lost: Not receiving heartbeat for 60 seconds\n",
      "25/03/11 09:52:47 ERROR TaskSchedulerImpl: Lost executor 41 on 172.24.0.4: worker lost: Not receiving heartbeat for 60 seconds\n",
      "25/03/11 10:26:47 WARN HeartbeatReceiver: Removing executor 42 with no recent heartbeats: 1961100 ms exceeds timeout 120000 ms\n",
      "25/03/11 10:26:47 WARN HeartbeatReceiver: Removing executor 43 with no recent heartbeats: 1959208 ms exceeds timeout 120000 ms\n",
      "25/03/11 10:26:47 ERROR TaskSchedulerImpl: Lost executor 42 on 172.24.0.4: Executor heartbeat timed out after 1961100 ms\n",
      "25/03/11 10:26:47 ERROR TaskSchedulerImpl: Lost executor 43 on 172.24.0.5: Executor heartbeat timed out after 1959208 ms\n",
      "25/03/11 11:00:00 ERROR TaskSchedulerImpl: Lost executor 44 on 172.24.0.4: worker lost: Not receiving heartbeat for 60 seconds\n",
      "25/03/11 11:00:00 ERROR TaskSchedulerImpl: Lost executor 45 on 172.24.0.5: worker lost: Not receiving heartbeat for 60 seconds\n",
      "25/03/11 11:31:23 ERROR TaskSchedulerImpl: Lost executor 47 on 172.24.0.5: worker lost: Not receiving heartbeat for 60 seconds\n",
      "25/03/11 11:31:23 ERROR TaskSchedulerImpl: Lost executor 46 on 172.24.0.4: worker lost: Not receiving heartbeat for 60 seconds\n",
      "25/03/11 11:53:54 WARN HeartbeatReceiver: Removing executor 48 with no recent heartbeats: 1333072 ms exceeds timeout 120000 ms\n",
      "25/03/11 11:53:54 ERROR TaskSchedulerImpl: Lost executor 48 on 172.24.0.4: Executor heartbeat timed out after 1333072 ms\n",
      "25/03/11 12:05:23 ERROR TaskSchedulerImpl: Lost executor 50 on 172.24.0.4: worker lost: Not receiving heartbeat for 60 seconds\n",
      "25/03/11 12:05:23 ERROR TaskSchedulerImpl: Lost executor 49 on 172.24.0.5: worker lost: Not receiving heartbeat for 60 seconds\n",
      "25/03/11 12:09:06 ERROR TaskSchedulerImpl: Lost executor 52 on 172.24.0.4: worker lost: Not receiving heartbeat for 60 seconds\n",
      "25/03/11 12:09:06 ERROR TaskSchedulerImpl: Lost executor 51 on 172.24.0.5: worker lost: Not receiving heartbeat for 60 seconds\n",
      "25/03/11 12:33:08 WARN HeartbeatReceiver: Removing executor 53 with no recent heartbeats: 1421377 ms exceeds timeout 120000 ms\n",
      "25/03/11 12:33:08 WARN HeartbeatReceiver: Removing executor 54 with no recent heartbeats: 1422185 ms exceeds timeout 120000 ms\n",
      "25/03/11 12:33:08 ERROR TaskSchedulerImpl: Lost executor 53 on 172.24.0.5: Executor heartbeat timed out after 1421377 ms\n",
      "25/03/11 12:33:08 ERROR TaskSchedulerImpl: Lost executor 54 on 172.24.0.4: Executor heartbeat timed out after 1422185 ms\n",
      "25/03/11 12:39:26 ERROR TaskSchedulerImpl: Lost executor 56 on 172.24.0.4: worker lost: Not receiving heartbeat for 60 seconds\n",
      "25/03/11 12:39:26 ERROR TaskSchedulerImpl: Lost executor 55 on 172.24.0.5: worker lost: Not receiving heartbeat for 60 seconds\n",
      "25/03/11 12:46:13 WARN HeartbeatReceiver: Removing executor 57 with no recent heartbeats: 385895 ms exceeds timeout 120000 ms\n",
      "25/03/11 12:46:13 WARN HeartbeatReceiver: Removing executor 58 with no recent heartbeats: 386991 ms exceeds timeout 120000 ms\n",
      "25/03/11 12:46:13 ERROR TaskSchedulerImpl: Lost executor 57 on 172.24.0.5: Executor heartbeat timed out after 385895 ms\n",
      "25/03/11 12:46:13 ERROR TaskSchedulerImpl: Lost executor 58 on 172.24.0.4: Executor heartbeat timed out after 386991 ms\n"
     ]
    }
   ],
   "source": [
    "!ls -lah notebooks/data/rentals_output/agency_name=SF\\ Cars | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the SparkContext\n",
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
