{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> <img src=\"../img/ITESOLogo.png\" alt=\"ITESO\" width=\"480\" height=\"130\"> </center>\n",
    "# <center> **Departamento de Electrónica, Sistemas e Informática** </center>\n",
    "---\n",
    "## <center> **Procesamiento de Datos Masivos** </center>\n",
    "---\n",
    "### <center> **Primavera 2025** </center>\n",
    "---\n",
    "### <center> **Lab 10** </center>\n",
    "\n",
    "---\n",
    "**Profesor**: Dr. Pablo Camarillo Ramirez </br>\n",
    "**Team**: Par de Dos  \n",
    "**Members**: Diego Orozco and Aarón Ortega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creacion de la conexión con el cluster de spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/05/04 19:10:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Lab10_ParDeDos\") \\\n",
    "    .master(\"spark://368ad5a83fd7:7077\") \\\n",
    "    .config(\"spark.ui.port\",\"4040\") \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparación de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from team_ParDeDos.spark_utils import SparkUtils as SpU\n",
    "# Columns: male,age,education,currentSmoker,cigsPerDay,BPMeds,prevalentStroke,prevalentHyp,diabetes,totChol,sysBP,diaBP,BMI,heartRate,glucose,TenYearCHD\n",
    "\n",
    "# Define schema for the DataFrame\n",
    "schema = SpU.generate_schema([\n",
    "        (\"male\", \"integer\"),\n",
    "        (\"age\", \"integer\"),\n",
    "        (\"education\", \"integer\"),\n",
    "        (\"currentSmoker\", \"integer\"),\n",
    "        (\"cigsPerDay\", \"integer\"),\n",
    "        (\"BPMeds\", \"integer\"),\n",
    "        (\"prevalentStroke\", \"integer\"),\n",
    "        (\"prevalentHyp\", \"integer\"),\n",
    "        (\"diabetes\", \"integer\"),\n",
    "        (\"totChol\", \"integer\"),\n",
    "        (\"sysBP\", \"integer\"),\n",
    "        (\"diaBP\", \"integer\"),\n",
    "        (\"BMI\", \"integer\"),\n",
    "        (\"heartRate\", \"integer\"),\n",
    "        (\"glucose\", \"integer\"),\n",
    "        (\"TenYearCHD\", \"double\")\n",
    "    ])\n",
    "\n",
    "# Create DataFrame\n",
    "framingham = spark \\\n",
    "                .read \\\n",
    "                .schema(schema) \\\n",
    "                .option(\"header\", \"true\") \\\n",
    "                .csv(\"/home/jovyan/notebooks/data/framingham.csv\")\n",
    "\n",
    "clean_framingham = SpU.clean_df(framingham, schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assemble the features into a single vector column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/04 19:10:46 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------------------------------------------------------------+\n",
      "|TenYearCHD|features                                                               |\n",
      "+----------+-----------------------------------------------------------------------+\n",
      "|0.0       |(15,[0,1,2,9,10,11,13,14],[1.0,39.0,4.0,195.0,106.0,70.0,80.0,77.0])   |\n",
      "|0.0       |(15,[1,2,9,10,11,13,14],[46.0,2.0,250.0,121.0,81.0,95.0,76.0])         |\n",
      "|0.0       |[1.0,48.0,1.0,1.0,20.0,0.0,0.0,0.0,0.0,245.0,0.0,80.0,0.0,75.0,70.0]   |\n",
      "|1.0       |[0.0,61.0,3.0,1.0,30.0,0.0,0.0,1.0,0.0,225.0,150.0,95.0,0.0,65.0,103.0]|\n",
      "|0.0       |[0.0,46.0,3.0,1.0,23.0,0.0,0.0,0.0,0.0,285.0,130.0,84.0,0.0,85.0,85.0] |\n",
      "+----------+-----------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "feature_columns = [\"male\", \"age\", \"education\", \"currentSmoker\", \"cigsPerDay\",\n",
    "                  \"BPMeds\", \"prevalentStroke\", \"prevalentHyp\", \"diabetes\",\n",
    "                  \"totChol\", \"sysBP\", \"diaBP\", \"BMI\", \"heartRate\", \"glucose\"]\n",
    "\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "\n",
    "data_with_features = assembler.transform(clean_framingham).select(\"TenYearCHD\", \"features\")\n",
    "\n",
    "data_with_features.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into training and test sets 80% training data and 20% testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = data_with_features.randomSplit([0.8, 0.2], seed=57)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset\n",
      "+----------+-----------------------------------------------------------------------+\n",
      "|TenYearCHD|features                                                               |\n",
      "+----------+-----------------------------------------------------------------------+\n",
      "|0.0       |(15,[0,1,2,9,10,11,13,14],[1.0,39.0,4.0,195.0,106.0,70.0,80.0,77.0])   |\n",
      "|0.0       |(15,[1,2,9,10,11,13,14],[46.0,2.0,250.0,121.0,81.0,95.0,76.0])         |\n",
      "|0.0       |[1.0,48.0,1.0,1.0,20.0,0.0,0.0,0.0,0.0,245.0,0.0,80.0,0.0,75.0,70.0]   |\n",
      "|1.0       |[0.0,61.0,3.0,1.0,30.0,0.0,0.0,1.0,0.0,225.0,150.0,95.0,0.0,65.0,103.0]|\n",
      "|0.0       |[0.0,46.0,3.0,1.0,23.0,0.0,0.0,0.0,0.0,285.0,130.0,84.0,0.0,85.0,85.0] |\n",
      "+----------+-----------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Trained Dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------------------------------------------------------+\n",
      "|TenYearCHD|features                                                         |\n",
      "+----------+-----------------------------------------------------------------+\n",
      "|0.0       |(15,[0,1,2,3,4,7,9,13],[1.0,35.0,1.0,1.0,40.0,1.0,265.0,102.0])  |\n",
      "|0.0       |(15,[0,1,2,3,4,7,9,13],[1.0,48.0,2.0,1.0,43.0,1.0,210.0,95.0])   |\n",
      "|0.0       |(15,[0,1,2,3,4,7,9,13],[1.0,56.0,1.0,1.0,43.0,1.0,240.0,80.0])   |\n",
      "|0.0       |(15,[0,1,2,3,4,7,11,13],[1.0,50.0,3.0,1.0,30.0,1.0,105.0,72.0])  |\n",
      "|0.0       |(15,[0,1,2,3,4,9,10,13],[1.0,43.0,2.0,1.0,20.0,153.0,130.0,63.0])|\n",
      "+----------+-----------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(\"Original Dataset\")\n",
    "data_with_features.show(5, truncate=False)\n",
    "\n",
    "# Print train dataset\n",
    "print(\"Trained Dataset\")\n",
    "train_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.01, featuresCol=\"features\", labelCol=\"TenYearCHD\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/04 19:11:28 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "25/05/04 19:11:28 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [0.44442997924738903,0.06437115942304895,-0.01714871123433243,0.08886663411378709,0.01858201585886688,0.38586930633634703,0.6647169872764429,0.6242157540959542,0.6658870920934002,0.001214638645979052,0.00014111070591105773,0.004235863452192114,-0.0064485174402852926,0.0002774134475905535,0.0033566675802193364]\n"
     ]
    }
   ],
   "source": [
    "lr_model = lr.fit(train_df)\n",
    "\n",
    "# Print coefficients\n",
    "print(\"Coefficients: \" + str(lr_model.coefficients))\n",
    "\n",
    "# Display model summary\n",
    "training_summary = lr_model.summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions\n",
      "+----------------------------------------------------------------+----------+-----------------------------------------+\n",
      "|features                                                        |prediction|probability                              |\n",
      "+----------------------------------------------------------------+----------+-----------------------------------------+\n",
      "|(15,[0,1,2,3,4,9,13,14],[1.0,39.0,2.0,1.0,20.0,212.0,87.0,77.0])|0.0       |[0.9360122009015007,0.06398779909849928] |\n",
      "|(15,[0,1,2,3,4,9,13,14],[1.0,39.0,2.0,1.0,20.0,222.0,73.0,64.0])|0.0       |[0.9380984781466017,0.061901521853398256]|\n",
      "|(15,[0,1,2,3,4,9,13,14],[1.0,43.0,1.0,1.0,20.0,206.0,86.0,89.0])|0.0       |[0.9149467215917397,0.08505327840826027] |\n",
      "|(15,[0,1,2,3,4,9,13,14],[1.0,47.0,3.0,1.0,25.0,173.0,68.0,75.0])|0.0       |[0.8958145134146775,0.10418548658532245] |\n",
      "|(15,[0,1,2,3,4,9,13,14],[1.0,54.0,2.0,1.0,30.0,215.0,60.0,75.0])|0.0       |[0.823770974567436,0.17622902543256402]  |\n",
      "+----------------------------------------------------------------+----------+-----------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "TenYearCHD\n",
      "+----------------------------------------------------------------+----------+\n",
      "|features                                                        |TenYearCHD|\n",
      "+----------------------------------------------------------------+----------+\n",
      "|(15,[0,1,2,3,4,9,13,14],[1.0,39.0,2.0,1.0,20.0,212.0,87.0,77.0])|0.0       |\n",
      "|(15,[0,1,2,3,4,9,13,14],[1.0,39.0,2.0,1.0,20.0,222.0,73.0,64.0])|0.0       |\n",
      "|(15,[0,1,2,3,4,9,13,14],[1.0,43.0,1.0,1.0,20.0,206.0,86.0,89.0])|0.0       |\n",
      "|(15,[0,1,2,3,4,9,13,14],[1.0,47.0,3.0,1.0,25.0,173.0,68.0,75.0])|0.0       |\n",
      "|(15,[0,1,2,3,4,9,13,14],[1.0,54.0,2.0,1.0,30.0,215.0,60.0,75.0])|0.0       |\n",
      "+----------------------------------------------------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use the trained model to make predictions on the test data\n",
    "predictions = lr_model.transform(test_df)\n",
    "\n",
    "# Show predictions\n",
    "print(\"Predictions\")\n",
    "predictions.select(\"features\", \"prediction\", \"probability\").show(5, truncate=False)\n",
    "\n",
    "print(\"TenYearCHD\")\n",
    "predictions.select(\"features\", \"TenYearCHD\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------+----------+----------+\n",
      "|features                                                               |TenYearCHD|prediction|\n",
      "+-----------------------------------------------------------------------+----------+----------+\n",
      "|[1.0,52.0,3.0,1.0,35.0,0.0,0.0,1.0,1.0,281.0,133.0,93.0,0.0,115.0,80.0]|0.0       |1.0       |\n",
      "|[1.0,53.0,1.0,1.0,10.0,0.0,0.0,1.0,1.0,229.0,0.0,82.0,0.0,60.0,172.0]  |0.0       |1.0       |\n",
      "|[1.0,58.0,2.0,1.0,60.0,0.0,0.0,1.0,0.0,250.0,150.0,97.0,32.0,75.0,65.0]|0.0       |1.0       |\n",
      "|[1.0,66.0,1.0,1.0,20.0,0.0,0.0,1.0,0.0,228.0,188.0,128.0,0.0,84.0,67.0]|0.0       |1.0       |\n",
      "|(15,[0,1,2,8,9,13,14],[1.0,62.0,3.0,1.0,346.0,80.0,394.0])             |1.0       |1.0       |\n",
      "|[0.0,67.0,2.0,0.0,0.0,1.0,0.0,1.0,1.0,303.0,204.0,96.0,0.0,75.0,394.0] |1.0       |1.0       |\n",
      "|[1.0,62.0,1.0,1.0,23.0,0.0,0.0,1.0,0.0,286.0,164.0,88.0,0.0,85.0,126.0]|1.0       |1.0       |\n",
      "|[1.0,63.0,1.0,0.0,0.0,0.0,0.0,1.0,1.0,260.0,0.0,98.0,0.0,67.0,109.0]   |1.0       |1.0       |\n",
      "|[1.0,63.0,1.0,1.0,20.0,0.0,1.0,1.0,0.0,213.0,163.0,94.0,0.0,76.0,69.0] |1.0       |1.0       |\n",
      "|[1.0,63.0,1.0,1.0,30.0,0.0,0.0,1.0,0.0,225.0,146.0,82.0,0.0,70.0,85.0] |1.0       |1.0       |\n",
      "+-----------------------------------------------------------------------+----------+----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+------------------------------------------------------------------+----------+----------+\n",
      "|features                                                          |TenYearCHD|prediction|\n",
      "+------------------------------------------------------------------+----------+----------+\n",
      "|(15,[0,1,2,3,4,9,13,14],[1.0,39.0,2.0,1.0,20.0,212.0,87.0,77.0])  |0.0       |0.0       |\n",
      "|(15,[0,1,2,3,4,9,13,14],[1.0,39.0,2.0,1.0,20.0,222.0,73.0,64.0])  |0.0       |0.0       |\n",
      "|(15,[0,1,2,3,4,9,13,14],[1.0,43.0,1.0,1.0,20.0,206.0,86.0,89.0])  |0.0       |0.0       |\n",
      "|(15,[0,1,2,3,4,9,13,14],[1.0,47.0,3.0,1.0,25.0,173.0,68.0,75.0])  |0.0       |0.0       |\n",
      "|(15,[0,1,2,3,4,9,13,14],[1.0,54.0,2.0,1.0,30.0,215.0,60.0,75.0])  |0.0       |0.0       |\n",
      "|(15,[0,1,2,7,9,10,13],[1.0,59.0,2.0,1.0,242.0,144.0,72.0])        |0.0       |0.0       |\n",
      "|(15,[0,1,2,7,9,10,13,14],[1.0,46.0,3.0,1.0,300.0,146.0,60.0,79.0])|0.0       |0.0       |\n",
      "|(15,[0,1,2,7,9,10,13,14],[1.0,48.0,1.0,1.0,245.0,144.0,75.0,77.0])|0.0       |0.0       |\n",
      "|(15,[0,1,2,7,9,10,13,14],[1.0,63.0,1.0,1.0,248.0,130.0,98.0,83.0])|0.0       |0.0       |\n",
      "|(15,[0,1,2,7,9,11,13],[1.0,42.0,4.0,1.0,245.0,85.0,62.0])         |0.0       |0.0       |\n",
      "+------------------------------------------------------------------+----------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show predictions and real values where prediction is 1\n",
    "predictions.filter(predictions.prediction == 1).select(\"features\", \"TenYearCHD\", \"prediction\").show(10, truncate=False)\n",
    "\n",
    "# Show predictions and real values where prediction is 0\n",
    "predictions.filter(predictions.prediction == 0).select(\"features\", \"TenYearCHD\", \"prediction\").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"TenYearCHD\", predictionCol=\"prediction\")\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions, {evaluator.metricName: \"accuracy\"})\n",
    "\n",
    "precision = evaluator.evaluate(predictions,{evaluator.metricName: \"weightedPrecision\"})\n",
    "\n",
    "recall = evaluator.evaluate(predictions,{evaluator.metricName: \"weightedRecall\"})\n",
    "\n",
    "f1 = evaluator.evaluate(predictions,{evaluator.metricName: \"f1\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8515\n",
      "Precision: 0.8212\n",
      "Recall: 0.8515\n",
      "F1 Score: 0.7944\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
