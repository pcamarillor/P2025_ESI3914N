{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# <center> <img src=\"../img/ITESOLogo.png\" alt=\"ITESO\" width=\"480\" height=\"130\"> </center>\n",
        "# <center> **Departamento de Electrónica, Sistemas e Informática** </center>\n",
        "---\n",
        "## <center> Program: _Computer Systems Engineering_  </center>\n",
        "---\n",
        "### <center> **Spring 2025** </center>\n",
        "---\n",
        "\n",
        "**Lab 04**: Generate Schemas Dynamically\n",
        "\n",
        "**Date**: 20/02/2025\n",
        "\n",
        "**Team Name**: Par De Dos\n",
        "\n",
        "**Professor**: Pablo Camarillo Ramirez"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize findspark to get acces to de PySpark installation\n",
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting default log level to \"WARN\".\n",
            "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
            "25/02/25 00:12:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Create connection to the spark cluster\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Lab 04 - Par de Dos\") \\\n",
        "    .master(\"spark://a52177ec73db:7077\") \\\n",
        "    .config(\"spark.ui.port\",\"4040\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Create SparkContext\n",
        "sc = spark.sparkContext\n",
        "sc.setLogLevel(\"ERROR\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[StructField('$name', StringType(), True),\n",
              " StructField('$age', IntegerType(), True),\n",
              " StructField('$city', StringType(), True)]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from team_ParDeDos.spark_utils import SparkUtils\n",
        "\n",
        "SparkUtils.generate_schema([(\"name\", \"StringType\"),\n",
        "                            (\"age\", \"IntegerType\"),\n",
        "                            (\"city\", \"StringType\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Stop the SparkContext\n",
        "sc.stop()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
