{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> **ITESO** </center>\n",
    "# <center> **Final Project Procesamiento de Datos Masivos** </center>\n",
    "---\n",
    "## <center> **Machine Learning Applications** </center>\n",
    "## <center> **Real-Time Stock Price Analysis** </center>\n",
    "---\n",
    "## <center> **Par de Foraneos** </center>\n",
    "---\n",
    "#### <center> **Spring 2025** </center>\n",
    "---\n",
    "#### <center> **05/14/2025** </center>\n",
    "\n",
    "---\n",
    "**Profesor**: Dr. Pablo Camarillo Ramirez\n",
    "**Students**: Eddie, Konrad, Diego, Aaron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this notebook, we'll apply machine learning to our processed stock price data. Having already set up the data streaming, collection, and preprocessing pipelines, we now focus on applying ML techniques to predict trading signals and evaluate trading strategies using backtesting.\n",
    "\n",
    "Our approach will be to:\n",
    "1. Either use our processed parquet files or download historical data\n",
    "2. Prepare the data with technical indicators and lag features\n",
    "3. Generate trading signals (BUY/SELL/WAIT) based on future price movements\n",
    "4. Train SVM models to predict these signals\n",
    "5. Optimize parameters using Optuna\n",
    "6. Backtest the trading strategy and evaluate performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'par_de_foraneos'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# import matplotlib.pyplot as plt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# from par_de_foraneos.stock_utils import load_and_prepare_data, generate_signals, \\\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#                                         StockModel, Model, Backtest\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpar_de_foraneos\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstock_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m resample_and_aggregate\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'par_de_foraneos'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from par_de_foraneos.stock_utils import load_and_prepare_data, generate_signals, \\\n",
    "                                        StockModel, Model, Backtest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Source Selection\n",
    "\n",
    "We can either use the parquet files generated by our streaming pipeline or download historical data directly from Yahoo Finance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the tickers we're working with\n",
    "STOCKS = ['CAT', 'AAPL', 'NVDA', 'CVX']\n",
    "\n",
    "# Choose data source: 'parquet' or 'historical'\n",
    "data_source = \"historical\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Each Stock\n",
    "\n",
    "Now we'll process each stock in our list using the StockModel class imported from stock_utils.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to True to optimize parameters, False to use default parameters\n",
    "optimize = True\n",
    "\n",
    "# Process each stock\n",
    "stock_models = {}\n",
    "backtest_results = {}\n",
    "\n",
    "for ticker in STOCKS:\n",
    "    print(f\"\\nProcessing {ticker}...\")\n",
    "    \n",
    "    # Initialize stock model\n",
    "    stock_model = StockModel(ticker, data_source=data_source)\n",
    "    \n",
    "    # Prepare data\n",
    "    success = stock_model.prepare_data()\n",
    "    if not success:\n",
    "        print(f\"Skipping {ticker} due to data preparation failure\")\n",
    "        continue\n",
    "    \n",
    "    # Optimize indicators if requested\n",
    "    if optimize:\n",
    "        print(f\"Optimizing indicators for {ticker}...\")\n",
    "        stock_model.optimize_indicators(n_trials=20)\n",
    "    \n",
    "    # Train model\n",
    "    print(f\"Training model for {ticker}...\")\n",
    "    stock_model.train_model()\n",
    "    \n",
    "    # Optimize backtest parameters if requested\n",
    "    if optimize:\n",
    "        print(f\"Optimizing backtest parameters for {ticker}...\")\n",
    "        stock_model.optimize_backtest(n_trials=20)\n",
    "    \n",
    "    # Run backtest\n",
    "    print(f\"Running backtest for {ticker}...\")\n",
    "    backtest_results[ticker] = stock_model.run_backtest()\n",
    "    \n",
    "    # Store model\n",
    "    stock_models[ticker] = stock_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portfolio Performance Analysis\n",
    "\n",
    "Now we'll analyze the performance of our portfolio, considering it as an equally-weighted portfolio of all the stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate portfolio metrics\n",
    "if len(backtest_results) > 0:\n",
    "    # Calculate average metrics\n",
    "    avg_calmar = sum(res['calmar'] for res in backtest_results.values()) / len(backtest_results)\n",
    "    avg_sharpe = sum(res['sharpe'] for res in backtest_results.values()) / len(backtest_results)\n",
    "    avg_sortino = sum(res['sortino'] for res in backtest_results.values()) / len(backtest_results)\n",
    "    avg_return = sum(res['return'] for res in backtest_results.values()) / len(backtest_results)\n",
    "    \n",
    "    # Calculate total portfolio value over time (equal weighting)\n",
    "    min_length = min(len(res['portfolio_value']) for res in backtest_results.values())\n",
    "    portfolio_values = np.zeros(min_length)\n",
    "    \n",
    "    for ticker, res in backtest_results.items():\n",
    "        # Normalize to percentage of initial investment\n",
    "        normalized_values = np.array(res['portfolio_value'][:min_length]) / res['portfolio_value'][0]\n",
    "        portfolio_values += normalized_values / len(backtest_results)\n",
    "    \n",
    "    # Scale back to dollars (assuming equal initial investment per stock)\n",
    "    initial_investment = 1_000_000  # $1M total, divided equally among stocks\n",
    "    per_stock_investment = initial_investment / len(backtest_results)\n",
    "    portfolio_values = portfolio_values * per_stock_investment\n",
    "    \n",
    "    print(\"\\n==== Portfolio Performance Summary ====\\n\")\n",
    "    print(f\"Number of stocks: {len(backtest_results)}\")\n",
    "    print(f\"Average Calmar Ratio: {avg_calmar:.4f}\")\n",
    "    print(f\"Average Sharpe Ratio: {avg_sharpe:.4f}\")\n",
    "    print(f\"Average Sortino Ratio: {avg_sortino:.4f}\")\n",
    "    print(f\"Average Return: {avg_return:.2f}%\")\n",
    "    print(f\"Initial Portfolio Value: ${initial_investment:,.2f}\")\n",
    "    print(f\"Final Portfolio Value: ${portfolio_values[-1]:,.2f}\")\n",
    "    print(f\"Total Return: {((portfolio_values[-1]/portfolio_values[0])-1)*100:.2f}%\")\n",
    "else:\n",
    "    print(\"No backtest results available for portfolio analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "Let's visualize the portfolio performance and each stock's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create portfolio value visualization\n",
    "if len(backtest_results) > 0:\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    \n",
    "    # Plot portfolio value\n",
    "    plt.plot(portfolio_values, label='Portfolio Value', linewidth=3, color='black')\n",
    "    \n",
    "    # Initial investment line\n",
    "    plt.axhline(y=initial_investment, color='r', linestyle='--', label='Initial Investment')\n",
    "    \n",
    "    plt.title('Portfolio Performance Over Time', fontsize=16)\n",
    "    plt.xlabel('Time Steps', fontsize=12)\n",
    "    plt.ylabel('Portfolio Value ($)', fontsize=12)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Individual stock performance\n",
    "    for ticker, res in backtest_results.items():\n",
    "        # Create figure with two y-axes\n",
    "        fig, ax1 = plt.subplots(figsize=(14, 7))\n",
    "        \n",
    "        # Plot portfolio value on left axis\n",
    "        color = 'tab:blue'\n",
    "        ax1.set_xlabel('Time Steps', fontsize=12)\n",
    "        ax1.set_ylabel('Portfolio Value ($)', color=color, fontsize=12)\n",
    "        ax1.plot(res['portfolio_value'], color=color, linewidth=2, label='Portfolio Value')\n",
    "        ax1.tick_params(axis='y', labelcolor=color)\n",
    "        ax1.axhline(y=res['initial_value'], color='r', linestyle='--', label='Initial Investment')\n",
    "        \n",
    "        # Create second y-axis for stock price\n",
    "        ax2 = ax1.twinx()\n",
    "        color = 'tab:orange'\n",
    "        ax2.set_ylabel('Stock Price ($)', color=color, fontsize=12)\n",
    "        ax2.plot(res['close_prices'], color=color, linewidth=1, alpha=0.7, label=f'{ticker} Price')\n",
    "        ax2.tick_params(axis='y', labelcolor=color)\n",
    "        \n",
    "        # Title and legend\n",
    "        plt.title(f'{ticker} - Portfolio Value vs Stock Price', fontsize=16)\n",
    "        \n",
    "        # Combined legend\n",
    "        lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "        lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "        ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper left')\n",
    "        \n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"No backtest results available for visualization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signal Distribution Analysis\n",
    "\n",
    "Let's analyze the distribution of trading signals for each stock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(stock_models) > 0:\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    for i, (ticker, model) in enumerate(stock_models.items()):\n",
    "        # Get signal counts\n",
    "        signal_counts = model.test_data['Signal'].value_counts()\n",
    "        \n",
    "        # Create subplot\n",
    "        plt.subplot(2, 2, i+1)\n",
    "        signal_counts.plot(kind='bar', color=['g', 'r', 'gray'])\n",
    "        plt.title(f'{ticker} Signal Distribution')\n",
    "        plt.ylabel('Count')\n",
    "        plt.xlabel('Signal Type')\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # Add count labels\n",
    "        for j, count in enumerate(signal_counts):\n",
    "            plt.text(j, count + 0.5, str(count), ha='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No signal distribution available for analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
