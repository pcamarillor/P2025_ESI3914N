{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> <img src=\"../../labs/img/ITESOLogo.png\" alt=\"ITESO\" width=\"480\" height=\"130\"> </center>\n",
    "# <center> **Departamento de Electrónica, Sistemas e Informática** </center>\n",
    "---\n",
    "## <center> **Big Data** </center>\n",
    "---\n",
    "### <center> **Spring 2025** </center>\n",
    "---\n",
    "### <center> **Kafka Producer: Financial Transaction Generator** </center>\n",
    "\n",
    "---\n",
    "**Profesor**: Dr. Pablo Camarillo Ramirez\n",
    "\n",
    "**Team members**: \n",
    "- Miguel Alberto Torres Dueñas\n",
    "- Juan Pablo Cortez Navarro\n",
    "- Luther Williams Sandria \n",
    "- Ferdinand Bierbaum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke the data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'grandeInformacion.streaming_generator'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkafka\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KafkaProducer\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgrandeInformacion\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstreaming_generator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generate_streaming_event\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'grandeInformacion.streaming_generator'"
     ]
    }
   ],
   "source": [
    "# from grandeInformacion.streaming_generator import generate_streaming_event\n",
    "import threading\n",
    "import logging\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "from kafka import KafkaProducer\n",
    "from grandeInformacion.streaming_generator import generate_streaming_event\n",
    "\n",
    "\n",
    "import random\n",
    "import time\n",
    "\n",
    "\n",
    "KAFKA_SERVER = '8285cadd2a48:9093'\n",
    "TEAM_SIZE = 4\n",
    "MIN_MESSAGES = 30\n",
    "MAX_MESSAGES = 150\n",
    "\n",
    "def create_producer():\n",
    "    return KafkaProducer(\n",
    "        bootstrap_servers=KAFKA_SERVER,\n",
    "        value_serializer=lambda v: json.dumps(v).encode('utf-8')\n",
    "    )\n",
    "\n",
    "def run_producer(producer_id):\n",
    "    topic_name = f'kafka-spark-example-{producer_id}'\n",
    "    log_filename = f'/home/jovyan/notebooks/data/logs/producer_{producer_id}_log.txt'\n",
    "    num_messages = random.randint(MIN_MESSAGES, MAX_MESSAGES)\n",
    "\n",
    "    logger = logging.getLogger(f'Producer-{producer_id}')\n",
    "    handler = logging.FileHandler(log_filename)\n",
    "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    handler.setFormatter(formatter)\n",
    "    logger.addHandler(handler)\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "    producer = create_producer()\n",
    "\n",
    "    logger.info(f\"Starting producer {producer_id} with {num_messages} messages to topic '{topic_name}'\")\n",
    "    print(f\"[Producer-{producer_id}] Sending {num_messages} messages to topic '{topic_name}'\")\n",
    "\n",
    "    try:\n",
    "        for i in range(num_messages):\n",
    "            data = generate_streaming_event()\n",
    "            producer.send(topic_name, data)\n",
    "            logger.info(f\"Sent message {i+1}: {data}\")\n",
    "            print(f\"[Producer-{producer_id}] Sent: {data}\")\n",
    "            time.sleep(2)\n",
    "        logger.info(f\"Finished. Total messages sent: {num_messages}\")\n",
    "    except KeyboardInterrupt:\n",
    "        logger.warning(\"Interrupted by user\")\n",
    "    finally:\n",
    "        producer.close()\n",
    "\n",
    "# Crear y lanzar hilos para cada productor\n",
    "if __name__ == \"__main__\":\n",
    "    threads = []\n",
    "    for i in range(TEAM_SIZE):\n",
    "        t = threading.Thread(target=run_producer, args=(i,))\n",
    "        threads.append(t)\n",
    "        t.start()\n",
    "\n",
    "    for t in threads:\n",
    "        t.join()\n",
    "\n",
    "    print(\"Todos los productores han terminado.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
