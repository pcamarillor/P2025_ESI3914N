{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2718b337",
   "metadata": {},
   "source": [
    "# <center> <img src=\"../../labs/img/ITESOLogo.png\" alt=\"ITESO\" width=\"480\" height=\"130\"> </center>\n",
    "# <center> **Departamento de Electrónica, Sistemas e Informática** </center>\n",
    "---\n",
    "## <center> **Big Data** </center>\n",
    "---\n",
    "### <center> **Spring 2025** </center>\n",
    "---\n",
    "### <center> **Application: Video Streaming Analytics** </center>\n",
    "---\n",
    "#### <center> **Live monitoring of video quality, viewer behavior, and content recommendations from services like Netflix or YouTube.** </center>\n",
    "\n",
    "# <center> <img src=\"https://upload.wikimedia.org/wikipedia/commons/e/ef/Youtube_logo.png\" width=\"640\" height=\"443\"> </center>\n",
    "---\n",
    "**Profesor**: Dr. Pablo Camarillo Ramirez\n",
    "\n",
    "**Team members**: \n",
    "- Miguel Alberto Torres Dueñas\n",
    "- Juan Pablo Cortez Navarro\n",
    "- Luther Williams Sandria \n",
    "- Ferdinand Bierbaum\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c35d804",
   "metadata": {},
   "source": [
    "# 1. Introduction and Problem Definition\n",
    "\n",
    "## Project's Objective\n",
    "Develop a real-time recommendation system for a streaming platform that:\n",
    "- Analyze user behavior (viewing time, pauses, skips, etc.)\n",
    "- Generate personalized recommendations using machine learning\n",
    "- Scale to handle large volumes of data\n",
    "\n",
    "## App's Description\n",
    "Our solution implements:\n",
    "- **Data Ingestion**: Consuming real-time visualization events from Kafka\n",
    "- **Processing**: Data transformation and enrichment with PySpark\n",
    "- **Modeling**: ALS (Alternating Least Squares) based recommendation system\n",
    "- **Visualization**: Dashboard in PowerBI with key metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06c1af4",
   "metadata": {},
   "source": [
    "# 2. Arquitectura del Sistema\n",
    "\n",
    "pongan el esquema aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd3203d",
   "metadata": {},
   "source": [
    "# 3. Justificación de las 5V's del Big Data\n",
    "\n",
    "### Volume\n",
    "- **Estimación de Crecimiento**:\n",
    "  \n",
    "  |    Time Perriod  | Data Processed |\n",
    "  |------------------|----------------|\n",
    "  | 1 Second         | 500 KB         |\n",
    "  | 1 Minute (60s)   | 30 MB          |\n",
    "  | 1 Hour (3,600s)  | 1.8 GB         |\n",
    "  | 1 Day (86,400s)  | 43.2 GB        |\n",
    "  | 1 Year (31.5M s) | 15.7 TB        |\n",
    "\n",
    "\n",
    "- **Management Strategies**:\n",
    "  - Data Partitioning in Parquet\n",
    "  - Distributed processing with Spark\n",
    "  - Schema optimization (appropriate data types)\n",
    "\n",
    "### Velocity\n",
    "- **Performance Metrics**:\n",
    "  - `processedRowsPerSecond`: X rows/second\n",
    "  - Latencia end-to-end: < X seconds for recommendations\n",
    "- **Techniques Implemented**:\n",
    "  - Structured Streaming with triggers each 3 seconds\n",
    "  - Checkpointing to ensure exactly-one-processing\n",
    "\n",
    "### Variety\n",
    "- **Data Schema**:\n",
    "```python\n",
    "root\n",
    " |-- user_id: string (nullable = true)\n",
    " |-- video_id: string (nullable = true)\n",
    " |-- watch_time_seconds: double (nullable = true)\n",
    " |-- resolution: string (nullable = true)\n",
    " |-- buffering_events: integer (nullable = true)\n",
    " |-- paused: boolean (nullable = true)\n",
    " |-- skipped: boolean (nullable = true)\n",
    " |-- genre: string (nullable = true)\n",
    " |-- timestamp: timestamp (nullable = true)\n",
    "```\n",
    "\n",
    "### Veracity\n",
    "- Schema validation when ingesting data\n",
    "- Filtering incomplete records\n",
    "- Quality metrics in PowerBI\n",
    "\n",
    "### Value\n",
    "- watch_time_seconds: User engagement\n",
    "- buffering_events: Quality of Experience\n",
    "- genre: Personal preferences\n",
    "- skipped: Non-relevant content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2a9313",
   "metadata": {},
   "source": [
    "# 4. Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ce40fc",
   "metadata": {},
   "source": [
    "## Spark Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8e960f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "#0be7b65b50a239d7ee8b621f3c329b25c5c4aadafbae5ac7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e808d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/conda/spark-3.5.4-bin-hadoop3-scala2.13/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "org.apache.spark#spark-sql-kafka-0-10_2.13 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-5af0a233-6c59-43c6-a9c6-25dc29bae959;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.spark#spark-sql-kafka-0-10_2.13;3.5.4 in central\n",
      "\tfound org.apache.spark#spark-token-provider-kafka-0-10_2.13;3.5.4 in central\n",
      "\tfound org.apache.kafka#kafka-clients;3.4.1 in central\n",
      "\tfound org.lz4#lz4-java;1.8.0 in central\n",
      "\tfound org.xerial.snappy#snappy-java;1.1.10.5 in central\n",
      "\tfound org.slf4j#slf4j-api;2.0.7 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-runtime;3.3.4 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-api;3.3.4 in central\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.0 in central\n",
      "\tfound org.scala-lang.modules#scala-parallel-collections_2.13;1.0.4 in central\n",
      "\tfound org.apache.commons#commons-pool2;2.11.1 in central\n",
      ":: resolution report :: resolve 731ms :: artifacts dl 37ms\n",
      "\t:: modules in use:\n",
      "\tcom.google.code.findbugs#jsr305;3.0.0 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\torg.apache.commons#commons-pool2;2.11.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-api;3.3.4 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-runtime;3.3.4 from central in [default]\n",
      "\torg.apache.kafka#kafka-clients;3.4.1 from central in [default]\n",
      "\torg.apache.spark#spark-sql-kafka-0-10_2.13;3.5.4 from central in [default]\n",
      "\torg.apache.spark#spark-token-provider-kafka-0-10_2.13;3.5.4 from central in [default]\n",
      "\torg.lz4#lz4-java;1.8.0 from central in [default]\n",
      "\torg.scala-lang.modules#scala-parallel-collections_2.13;1.0.4 from central in [default]\n",
      "\torg.slf4j#slf4j-api;2.0.7 from central in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.10.5 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   12  |   0   |   0   |   0   ||   12  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-5af0a233-6c59-43c6-a9c6-25dc29bae959\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 12 already retrieved (0kB/21ms)\n",
      "25/05/14 00:53:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SparkSQLStructuredStreaming-Kafka\") \\\n",
    "    .master(\"spark://7a8106b8550d:7077\") \\\n",
    "    .config(\"spark.ui.port\",\"4040\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.13:3.5.4\") \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3549704a",
   "metadata": {},
   "source": [
    "## Kafka Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc4d173b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: binary (nullable = true)\n",
      " |-- value: binary (nullable = true)\n",
      " |-- topic: string (nullable = true)\n",
      " |-- partition: integer (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- timestampType: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kafka_lines = spark \\\n",
    "                .readStream \\\n",
    "                .format(\"kafka\") \\\n",
    "                .option(\"kafka.bootstrap.servers\", \"ed69dac0a4e4:9093\") \\\n",
    "                .option(\"subscribe\", \"kafka-spark-example-0\") \\\n",
    "                .option(\"subscribe\", \"kafka-spark-example-1\") \\\n",
    "                .option(\"subscribe\", \"kafka-spark-example-2\") \\\n",
    "                .option(\"subscribe\", \"kafka-spark-example-3\") \\\n",
    "                .load()\n",
    "\n",
    "kafka_lines.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cd106a",
   "metadata": {},
   "source": [
    "## Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e9101b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- pairs_array: array (nullable = true)\n",
      " |    |-- element: string (containsNull = false)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- video_id: string (nullable = true)\n",
      " |-- watch_time_seconds: string (nullable = true)\n",
      " |-- resolution: string (nullable = true)\n",
      " |-- bitrate_kbps: string (nullable = true)\n",
      " |-- buffering_events: string (nullable = true)\n",
      " |-- paused: string (nullable = true)\n",
      " |-- skipped: string (nullable = true)\n",
      " |-- genre: string (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      " |-- recommended: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import split, col, expr\n",
    "\n",
    "kafka_df = kafka_lines.select(split(col(\"value\"), \",\").alias(\"pairs_array\"))\n",
    "\n",
    "kafka_df = kafka_df.withColumn(\"user_id\", split(col(\"pairs_array\").getItem(0), \":\").getItem(1))\n",
    "kafka_df = kafka_df.withColumn(\"video_id\", split(col(\"pairs_array\").getItem(1), \":\").getItem(1))\n",
    "kafka_df = kafka_df.withColumn(\"watch_time_seconds\", split(col(\"pairs_array\").getItem(2), \":\").getItem(1))\n",
    "kafka_df = kafka_df.withColumn(\"resolution\", split(col(\"pairs_array\").getItem(3), \":\").getItem(1))\n",
    "kafka_df = kafka_df.withColumn(\"bitrate_kbps\", split(col(\"pairs_array\").getItem(4), \":\").getItem(1))\n",
    "kafka_df = kafka_df.withColumn(\"buffering_events\", split(col(\"pairs_array\").getItem(5), \":\").getItem(1))\n",
    "kafka_df = kafka_df.withColumn(\"paused\", split(col(\"pairs_array\").getItem(6), \":\").getItem(1))\n",
    "kafka_df = kafka_df.withColumn(\"skipped\", split(col(\"pairs_array\").getItem(7), \":\").getItem(1))\n",
    "kafka_df = kafka_df.withColumn(\"genre\", split(col(\"pairs_array\").getItem(8), \":\").getItem(1))\n",
    "kafka_df = kafka_df.withColumn(\"region\", split(col(\"pairs_array\").getItem(9), \":\").getItem(1))\n",
    "kafka_df = kafka_df.withColumn(\"recommended\", split(col(\"pairs_array\").getItem(10), \":\").getItem(1))\n",
    "\n",
    "# Usamos expr para hacer la resta de longitud directamente\n",
    "kafka_df = kafka_df.withColumn(\n",
    "    \"timestamp\",\n",
    "    expr(\"substring(split(pairs_array[11], ':')[1], 1, length(split(pairs_array[11], ':')[1]) - 1)\")\n",
    ")\n",
    "\n",
    "kafka_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c63df52",
   "metadata": {},
   "source": [
    "## Streaming processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8b97666",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/14 00:53:45 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n",
      "25/05/14 00:53:46 WARN AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.\n",
      "25/05/14 00:53:50 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000 milliseconds, but spent 4208 milliseconds\n",
      "25/05/14 00:53:53 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000 milliseconds, but spent 3703 milliseconds\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "query_files = kafka_df \\\n",
    "                .writeStream \\\n",
    "                .outputMode(\"append\") \\\n",
    "                .trigger(processingTime='3 seconds') \\\n",
    "                .format(\"parquet\") \\\n",
    "                .option(\"path\", \"/home/jovyan/notebooks/data/project_parquet\") \\\n",
    "                .option(\"truncate\", \"false\") \\\n",
    "                .option(\"checkpointLocation\", \"/home/jovyan/checkpoint\") \\\n",
    "                .start()\n",
    "query_files.awaitTermination(300)\n",
    "query_files.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62d10ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+----------+------------------+----------+------------+----------------+------+-------+--------------+------+-----------+-------------+\n",
      "|pairs_array                                                                                                                                                                                                                                                                         |user_id     |video_id  |watch_time_seconds|resolution|bitrate_kbps|buffering_events|paused|skipped|genre         |region|recommended|timestamp    |\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+----------+------------------+----------+------------+----------------+------+-------+--------------+------+-----------+-------------+\n",
      "|[{\"user_id\": \"user_5232\",  \"video_id\": \"vid_021\",  \"watch_time_seconds\": 188,  \"resolution\": \"1080p\",  \"bitrate_kbps\": 3765,  \"buffering_events\": 5,  \"paused\": true,  \"skipped\": true,  \"genre\": \"Documentary\",  \"region\": \"JP\",  \"recommended\": true,  \"timestamp\": \"05/14/2025\"}]| \"user_5232\"| \"vid_021\"| 188              | \"1080p\"  | 3765       | 5              | true | true  | \"Documentary\"| \"JP\" | true      | \"05/14/2025\"|\n",
      "|[{\"user_id\": \"user_2262\",  \"video_id\": \"vid_051\",  \"watch_time_seconds\": 2428,  \"resolution\": \"1080p\",  \"bitrate_kbps\": 2139,  \"buffering_events\": 1,  \"paused\": true,  \"skipped\": true,  \"genre\": \"Comedy\",  \"region\": \"JP\",  \"recommended\": false,  \"timestamp\": \"05/14/2025\"}]   | \"user_2262\"| \"vid_051\"| 2428             | \"1080p\"  | 2139       | 1              | true | true  | \"Comedy\"     | \"JP\" | false     | \"05/14/2025\"|\n",
      "|[{\"user_id\": \"user_8935\",  \"video_id\": \"vid_075\",  \"watch_time_seconds\": 813,  \"resolution\": \"720p\",  \"bitrate_kbps\": 4245,  \"buffering_events\": 2,  \"paused\": true,  \"skipped\": false,  \"genre\": \"Documentary\",  \"region\": \"DE\",  \"recommended\": true,  \"timestamp\": \"05/14/2025\"}]| \"user_8935\"| \"vid_075\"| 813              | \"720p\"   | 4245       | 2              | true | false | \"Documentary\"| \"DE\" | true      | \"05/14/2025\"|\n",
      "|[{\"user_id\": \"user_2928\",  \"video_id\": \"vid_067\",  \"watch_time_seconds\": 328,  \"resolution\": \"480p\",  \"bitrate_kbps\": 3356,  \"buffering_events\": 5,  \"paused\": true,  \"skipped\": true,  \"genre\": \"Sci-Fi\",  \"region\": \"MX\",  \"recommended\": true,  \"timestamp\": \"05/14/2025\"}]      | \"user_2928\"| \"vid_067\"| 328              | \"480p\"   | 3356       | 5              | true | true  | \"Sci-Fi\"     | \"MX\" | true      | \"05/14/2025\"|\n",
      "|[{\"user_id\": \"user_6080\",  \"video_id\": \"vid_025\",  \"watch_time_seconds\": 1837,  \"resolution\": \"4K\",  \"bitrate_kbps\": 2265,  \"buffering_events\": 4,  \"paused\": true,  \"skipped\": false,  \"genre\": \"Documentary\",  \"region\": \"UK\",  \"recommended\": false,  \"timestamp\": \"05/14/2025\"}]| \"user_6080\"| \"vid_025\"| 1837             | \"4K\"     | 2265       | 4              | true | false | \"Documentary\"| \"UK\" | false     | \"05/14/2025\"|\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+----------+------------------+----------+------------+----------------+------+-------+--------------+------+-----------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(\"/home/jovyan/notebooks/data/project_parquet\")\n",
    "df.show(5, False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf5de13",
   "metadata": {},
   "source": [
    "## Machine Learning Model - ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33e7d5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+-------------------+\n",
      "|user_id_int|video_id_int|  implicit_feedback|\n",
      "+-----------+------------+-------------------+\n",
      "|       5232|          21| 0.2813333333333333|\n",
      "|       2262|          51| 0.7746666666666666|\n",
      "|       8935|          75| 0.4754999999999999|\n",
      "|       2928|          67|0.30466666666666664|\n",
      "|       6080|          25| 0.5861666666666667|\n",
      "+-----------+------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, regexp_extract, when\n",
    "\n",
    "# Leer datos Parquet\n",
    "video_data = spark.read.parquet(\"/home/jovyan/notebooks/data/project_parquet\")\n",
    "\n",
    "# Convertir tipos de datos correctamente\n",
    "video_data = video_data.withColumn(\"watch_time_seconds\", col(\"watch_time_seconds\").cast(\"double\")) \\\n",
    "                      .withColumn(\"buffering_events\", col(\"buffering_events\").cast(\"double\")) \\\n",
    "                      .withColumn(\"skipped\", when(col(\"skipped\") == \"true\", 1).otherwise(0))\n",
    "\n",
    "# Crear IDs numéricos (como lo tienes)\n",
    "video_data = video_data.withColumn(\"user_id_int\", regexp_extract(col(\"user_id\"), \"user_(\\\\d+)\", 1).cast(\"integer\")) \\\n",
    "                      .withColumn(\"video_id_int\", regexp_extract(col(\"video_id\"), \"vid_(\\\\d+)\", 1).cast(\"integer\"))\n",
    "\n",
    "# Crear métrica de feedback implícito (versión corregida)\n",
    "video_data = video_data.withColumn(\"implicit_feedback\", \n",
    "                                 (col(\"watch_time_seconds\")/3600 * 0.6 +  # Tiempo de visualización en horas\n",
    "                                  (1 - col(\"buffering_events\")/10) * 0.3 +  # Inverso de buffering\n",
    "                                  (1 - col(\"skipped\")) * 0.1))  # No saltado\n",
    "\n",
    "# Verificar datos\n",
    "video_data.select(\"user_id_int\", \"video_id_int\", \"implicit_feedback\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08e5c6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "als = ALS(\n",
    "    userCol=\"user_id_int\",\n",
    "    itemCol=\"video_id_int\",\n",
    "    ratingCol=\"implicit_feedback\",\n",
    "    implicitPrefs=True,  # Usar feedback implícito\n",
    "    coldStartStrategy=\"drop\",  # Manejar nuevos usuarios/videos\n",
    "    nonnegative=True,  # Solo factores positivos\n",
    "    rank=10,  # Factores latentes (ajustable)\n",
    "    maxIter=15,  # Iteraciones (ajustable)\n",
    "    regParam=0.1  # Regularización (ajustable)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c94e214c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/14 00:59:17 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "25/05/14 00:59:17 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n"
     ]
    }
   ],
   "source": [
    "# Entrenar modelo\n",
    "model = als.fit(video_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dec19eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recomendaciones para usuarios de ejemplo:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------------------------------------------------------------------------------------------+\n",
      "|user_id_int|recommendations                                                                                  |\n",
      "+-----------+-------------------------------------------------------------------------------------------------+\n",
      "|6080       |[{51, 0.38348034}, {1, 0.3802694}, {25, 0.28687268}, {67, 0.049135257}, {58, 0.026772548}]       |\n",
      "|7321       |[{60, 0.50269973}, {86, 0.44174686}, {100, 0.3505718}, {43, 0.029861854}, {67, 0.008550466}]     |\n",
      "|2391       |[{95, 0.48697206}, {66, 0.38709062}, {7, 0.29938403}, {73, 0.06898091}, {13, 1.0658878E-6}]      |\n",
      "|9811       |[{37, 0.5696879}, {13, 0.53095186}, {21, 0.16064978}, {1, 4.3297778E-6}, {60, 9.962939E-7}]      |\n",
      "|9531       |[{58, 0.8010914}, {74, 0.3921574}, {25, 0.02575272}, {7, 1.2776397E-4}, {31, 9.470557E-5}]       |\n",
      "|9442       |[{3, 0.89450336}, {79, 0.18814947}, {74, 0.016068548}, {100, 5.4950247E-6}, {95, 2.4708405E-7}]  |\n",
      "|2502       |[{95, 0.61299217}, {66, 0.48726314}, {7, 0.37685955}, {73, 0.086831994}, {13, 1.3417215E-6}]     |\n",
      "|7112       |[{37, 0.61116195}, {13, 0.5696058}, {21, 0.17234528}, {1, 4.644991E-6}, {60, 1.0688253E-6}]      |\n",
      "|2262       |[{51, 0.50261194}, {1, 0.49840346}, {25, 0.37486422}, {67, 0.064399555}, {84, 3.9683773E-6}]     |\n",
      "|5522       |[{36, 0.53211945}, {73, 0.26020476}, {95, 0.082945384}, {66, 0.0659327}, {7, 0.050993737}]       |\n",
      "|5232       |[{37, 0.16913867}, {13, 0.15763804}, {21, 0.047696445}, {97, 2.2682569E-5}, {84, 2.1900256E-5}]  |\n",
      "|8072       |[{60, 0.57211554}, {86, 0.5027459}, {100, 0.39898086}, {43, 0.033985358}, {67, 0.009731165}]     |\n",
      "|5933       |[{97, 0.5583856}, {84, 0.5391271}, {75, 0.33293688}, {43, 0.035774503}, {21, 2.5706271E-5}]      |\n",
      "|8334       |[{30, 0.7897582}, {83, 0.4756311}, {76, 4.2253235E-4}, {74, 2.9984466E-4}, {67, 1.7810667E-4}]   |\n",
      "|6825       |[{60, 0.39897928}, {86, 0.35060263}, {100, 0.27823943}, {43, 0.023700552}, {67, 0.0067862747}]   |\n",
      "|8935       |[{97, 0.33253735}, {84, 0.32106826}, {75, 0.19827506}, {43, 0.021304915}, {21, 1.5308946E-5}]    |\n",
      "|2905       |[{36, 0.0018336837}, {73, 8.56177E-4}, {30, 4.662344E-4}, {83, 2.8078922E-4}, {76, 3.7264922E-6}]|\n",
      "|3935       |[{97, 0.53909564}, {84, 0.52050245}, {75, 0.32143524}, {43, 0.034538638}, {21, 2.481822E-5}]     |\n",
      "|9535       |[{95, 0.3777763}, {66, 0.30029172}, {7, 0.232252}, {73, 0.053513035}, {98, 2.1936695E-4}]        |\n",
      "|6086       |[{58, 0.55367595}, {74, 0.27139464}, {3, 0.019713039}, {25, 0.017799044}, {79, 0.0041464325}]    |\n",
      "+-----------+-------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "\n",
      "Top 5 recomendaciones para usuario 8072:\n",
      "+-----------+--------------------------------------------------------------------------------------------+\n",
      "|user_id_int|recommendations                                                                             |\n",
      "+-----------+--------------------------------------------------------------------------------------------+\n",
      "|8072       |[{60, 0.57211554}, {86, 0.5027459}, {100, 0.39898086}, {43, 0.033985358}, {67, 0.009731165}]|\n",
      "+-----------+--------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Recomendaciones para todos los usuarios (top 10)\n",
    "user_recs = model.recommendForAllUsers(5)\n",
    "\n",
    "# Mostrar recomendaciones para algunos usuarios\n",
    "print(\"Recomendaciones para usuarios de ejemplo:\")\n",
    "user_recs.show(truncate=False)\n",
    "\n",
    "# Recomendaciones para un usuario específico\n",
    "user_id_ejemplo = 8072\n",
    "recs_usuario = model.recommendForUserSubset(\n",
    "    spark.createDataFrame([(user_id_ejemplo,)]).toDF(\"user_id_int\"), \n",
    "    5\n",
    ")\n",
    "print(f\"\\nTop 5 recomendaciones para usuario {user_id_ejemplo}:\")\n",
    "recs_usuario.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2a8688",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+----------+------------------+----------+------------+----------------+------+-------+--------------+------+-----------+-------------+-----------+------------+-------------------+-----+------------+\n",
      "|         pairs_array|     user_id|  video_id|watch_time_seconds|resolution|bitrate_kbps|buffering_events|paused|skipped|         genre|region|recommended|    timestamp|user_id_int|video_id_int|  implicit_feedback|label|  prediction|\n",
      "+--------------------+------------+----------+------------------+----------+------------+----------------+------+-------+--------------+------+-----------+-------------+-----------+------------+-------------------+-----+------------+\n",
      "|[{\"user_id\": \"use...| \"user_6825\"| \"vid_100\"|            1609.0|      \"4K\"|        7104|             4.0|  true|      0|      \"Sci-Fi\"|  \"BR\"|       true| \"05/14/2025\"|       6825|         100| 0.5481666666666667|    1|  0.27823943|\n",
      "|[{\"user_id\": \"use...| \"user_8935\"| \"vid_075\"|             813.0|    \"720p\"|        4245|             2.0|  true|      0| \"Documentary\"|  \"DE\"|       true| \"05/14/2025\"|       8935|          75| 0.4754999999999999|    0|  0.19827506|\n",
      "|[{\"user_id\": \"use...| \"user_9442\"| \"vid_003\"|             348.0|   \"1080p\"|        2442|             5.0|  true|      0| \"Documentary\"|  \"MX\"|      false| \"05/14/2025\"|       9442|           3|              0.308|    0|  0.89450336|\n",
      "|[{\"user_id\": \"use...| \"user_2502\"| \"vid_095\"|            3507.0|      \"4K\"|        3076|             3.0| false|      0|      \"Horror\"|  \"DE\"|      false| \"05/14/2025\"|       2502|          95| 0.8944999999999999|    1|  0.61299217|\n",
      "|[{\"user_id\": \"use...| \"user_5649\"| \"vid_098\"|             347.0|    \"480p\"|        6258|             4.0| false|      0|       \"Drama\"|  \"UK\"|       true| \"05/14/2025\"|       5649|          98| 0.3378333333333333|    0|    0.735055|\n",
      "|[{\"user_id\": \"use...| \"user_2391\"| \"vid_066\"|            1161.0|      \"4K\"|        4116|             1.0| false|      0|      \"Horror\"|  \"JP\"|       true| \"05/14/2025\"|       2391|          66|             0.5635|    1|  0.38709062|\n",
      "|[{\"user_id\": \"use...| \"user_5933\"| \"vid_097\"|            3342.0|    \"480p\"|        1727|             3.0| false|      0|       \"Drama\"|  \"IN\"|      false| \"05/14/2025\"|       5933|          97| 0.8669999999999999|    1|   0.5583856|\n",
      "|[{\"user_id\": \"use...| \"user_4137\"| \"vid_083\"|            3401.0|   \"1080p\"|        5578|             0.0|  true|      0|       \"Drama\"|  \"IN\"|      false| \"05/14/2025\"|       4137|          83| 0.9668333333333333|    1|    0.389129|\n",
      "|[{\"user_id\": \"use...| \"user_6086\"| \"vid_074\"|            2028.0|   \"1080p\"|        2845|             0.0| false|      0|      \"Horror\"|  \"JP\"|       true| \"05/14/2025\"|       6086|          74|              0.738|    1|   0.2713946|\n",
      "|[{\"user_id\": \"use...| \"user_7112\"| \"vid_037\"|            2645.0|    \"720p\"|        1858|             3.0|  true|      0|      \"Action\"|  \"UK\"|       true| \"05/14/2025\"|       7112|          37| 0.7508333333333334|    1|  0.61116195|\n",
      "|[{\"user_id\": \"use...| \"user_6369\"| \"vid_031\"|            2818.0|    \"480p\"|        7316|             0.0| false|      0| \"Documentary\"|  \"UK\"|      false| \"05/14/2025\"|       6369|          31| 0.8696666666666667|    1|  0.37399632|\n",
      "|[{\"user_id\": \"use...| \"user_9811\"| \"vid_013\"|            1337.0|    \"720p\"|        2691|             0.0|  true|      0| \"Documentary\"|  \"JP\"|       true| \"05/14/2025\"|       9811|          13| 0.6228333333333332|    1|  0.53095186|\n",
      "|[{\"user_id\": \"use...| \"user_2262\"| \"vid_051\"|            2428.0|   \"1080p\"|        2139|             1.0|  true|      0|      \"Comedy\"|  \"JP\"|      false| \"05/14/2025\"|       2262|          51| 0.7746666666666666|    1|  0.50261194|\n",
      "|[{\"user_id\": \"use...| \"user_6080\"| \"vid_025\"|            1837.0|      \"4K\"|        2265|             4.0|  true|      0| \"Documentary\"|  \"UK\"|      false| \"05/14/2025\"|       6080|          25| 0.5861666666666667|    1|  0.28687268|\n",
      "|[{\"user_id\": \"use...| \"user_8334\"| \"vid_030\"|            2837.0|    \"480p\"|        1124|             2.0|  true|      0|       \"Drama\"|  \"BR\"|       true| \"05/14/2025\"|       8334|          30| 0.8128333333333332|    1|   0.7897582|\n",
      "|[{\"user_id\": \"use...| \"user_2928\"| \"vid_067\"|             328.0|    \"480p\"|        3356|             5.0|  true|      0|      \"Sci-Fi\"|  \"MX\"|       true| \"05/14/2025\"|       2928|          67|0.30466666666666664|    0| 0.007909455|\n",
      "|[{\"user_id\": \"use...| \"user_9531\"| \"vid_058\"|            1001.0|    \"480p\"|        6563|             4.0|  true|      0|       \"Drama\"|  \"IN\"|      false| \"05/14/2025\"|       9531|          58| 0.4468333333333333|    0|   0.8010914|\n",
      "|[{\"user_id\": \"use...| \"user_9535\"| \"vid_007\"|             871.0|   \"1080p\"|         970|             3.0| false|      0|      \"Sci-Fi\"|  \"MX\"|      false| \"05/14/2025\"|       9535|           7| 0.4551666666666666|    0|    0.232252|\n",
      "|[{\"user_id\": \"use...| \"user_6566\"| \"vid_036\"|             402.0|   \"1080p\"|        1447|             3.0|  true|      0|      \"Sci-Fi\"|  \"UK\"|       true| \"05/14/2025\"|       6566|          36|              0.377|    0|  0.80382735|\n",
      "|[{\"user_id\": \"use...| \"user_5232\"| \"vid_021\"|             188.0|   \"1080p\"|        3765|             5.0|  true|      0| \"Documentary\"|  \"JP\"|       true| \"05/14/2025\"|       5232|          21| 0.2813333333333333|    0| 0.047696445|\n",
      "|[{\"user_id\": \"use...| \"user_3917\"| \"vid_058\"|            2399.0|   \"1080p\"|        5232|             0.0| false|      0|      \"Action\"|  \"MX\"|       true| \"05/14/2025\"|       3917|          58| 0.7998333333333333|    1|  0.83361214|\n",
      "|[{\"user_id\": \"use...| \"user_8072\"| \"vid_060\"|            3508.0|      \"4K\"|         998|             2.0| false|      0|      \"Sci-Fi\"|  \"BR\"|       true| \"05/14/2025\"|       8072|          60| 0.9246666666666666|    1|  0.57211554|\n",
      "|[{\"user_id\": \"use...| \"user_7188\"| \"vid_030\"|            1865.0|   \"1080p\"|        4607|             5.0|  true|      0|      \"Action\"|  \"UK\"|      false| \"05/14/2025\"|       7188|          30| 0.5608333333333333|    1|   0.7638307|\n",
      "|[{\"user_id\": \"use...| \"user_2905\"| \"vid_076\"|             252.0|      \"4K\"|        6573|             5.0| false|      0|      \"Horror\"|  \"JP\"|       true| \"05/14/2025\"|       2905|          76|0.29200000000000004|    0|3.7264922E-6|\n",
      "|[{\"user_id\": \"use...| \"user_7321\"| \"vid_086\"|            2751.0|    \"480p\"|        5617|             5.0| false|      0|      \"Action\"|  \"MX\"|      false| \"05/14/2025\"|       7321|          86| 0.7084999999999999|    1|  0.44174686|\n",
      "|[{\"user_id\": \"use...| \"user_8507\"| \"vid_036\"|            3061.0|      \"4K\"|        2834|             5.0| false|      0|      \"Action\"|  \"BR\"|       true| \"05/14/2025\"|       8507|          36| 0.7601666666666667|    1|  0.83968556|\n",
      "|[{\"user_id\": \"use...| \"user_2067\"| \"vid_043\"|             408.0|      \"4K\"|        3278|             5.0|  true|      0|      \"Horror\"|  \"MX\"|       true| \"05/14/2025\"|       2067|          43|0.31799999999999995|    0| 0.004080641|\n",
      "|[{\"user_id\": \"use...| \"user_4668\"| \"vid_003\"|            2740.0|    \"720p\"|        7966|             3.0|  true|      0|       \"Drama\"|  \"DE\"|       true| \"05/14/2025\"|       4668|           3| 0.7666666666666666|    1|   0.9196932|\n",
      "|[{\"user_id\": \"use...| \"user_5522\"| \"vid_073\"|            2294.0|      \"4K\"|        2468|             2.0|  true|      0|      \"Comedy\"|  \"UK\"|       true| \"05/14/2025\"|       5522|          73| 0.7223333333333334|    1|  0.26020476|\n",
      "|[{\"user_id\": \"use...| \"user_3935\"| \"vid_084\"|            3110.0|   \"1080p\"|        2703|             4.0|  true|      0|       \"Drama\"|  \"JP\"|      false| \"05/14/2025\"|       3935|          84| 0.7983333333333332|    1|  0.52050245|\n",
      "+--------------------+------------+----------+------------------+----------+------------+----------------+------+-------+--------------+------+-----------+-------------+-----------+------------+-------------------+-----+------------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Hacer predicciones\n",
    "predictions = model.transform(video_data)\n",
    "predictions.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b74dc8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RMSE del modelo: 0.3187478627985201\n"
     ]
    }
   ],
   "source": [
    "# Evaluar con RMSE\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\",\n",
    "    labelCol=\"implicit_feedback\",\n",
    "    predictionCol=\"prediction\"\n",
    ")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"\\nRMSE del modelo: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3115aa7c",
   "metadata": {},
   "source": [
    "# 5. Results and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a85d78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "\n",
    "# Prepare data\n",
    "video_data = video_data.withColumn(\"label\", \n",
    "                                 expr(\"CASE WHEN implicit_feedback >= 0.5 THEN 1 ELSE 0 END\"))\n",
    "\n",
    "# Features\n",
    "feature_cols = [\"watch_time_seconds\", \"buffering_events\", \"skipped\", \"user_id_int\", \"video_id_int\"]\n",
    "\n",
    "# Change genre and region in indexes\n",
    "genre_indexer = StringIndexer(inputCol=\"genre\", outputCol=\"genre_index\")\n",
    "region_indexer = StringIndexer(inputCol=\"region\", outputCol=\"region_index\")\n",
    "\n",
    "# Assembler\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=feature_cols + [\"genre_index\", \"region_index\"],\n",
    "    outputCol=\"features\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8176623",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset\n",
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|    0|[188.0,5.0,0.0,52...|\n",
      "|    1|[2428.0,1.0,0.0,2...|\n",
      "|    0|[813.0,2.0,0.0,89...|\n",
      "|    0|[328.0,5.0,0.0,29...|\n",
      "|    1|[1837.0,4.0,0.0,6...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "Train set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1384:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|    0|[328.0,5.0,0.0,29...|\n",
      "|    0|[402.0,3.0,0.0,65...|\n",
      "|    0|[813.0,2.0,0.0,89...|\n",
      "|    0|[871.0,3.0,0.0,95...|\n",
      "|    1|[1161.0,1.0,0.0,2...|\n",
      "|    1|[1337.0,0.0,0.0,9...|\n",
      "|    1|[1609.0,4.0,0.0,6...|\n",
      "|    1|[2645.0,3.0,0.0,7...|\n",
      "|    1|[2818.0,0.0,0.0,6...|\n",
      "|    1|[3342.0,3.0,0.0,5...|\n",
      "|    1|[3401.0,0.0,0.0,4...|\n",
      "|    1|[3507.0,3.0,0.0,2...|\n",
      "|    1|[3508.0,2.0,0.0,8...|\n",
      "|    0|[252.0,5.0,0.0,29...|\n",
      "|    1|[1865.0,5.0,0.0,7...|\n",
      "|    1|[3061.0,5.0,0.0,8...|\n",
      "|    1|[3110.0,4.0,0.0,3...|\n",
      "+-----+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Apply transformations\n",
    "data_label = genre_indexer.fit(video_data).transform(video_data)\n",
    "data_label = region_indexer.fit(data_label).transform(data_label)\n",
    "data_with_features = assembler.transform(data_label).select(\"label\", \"features\")\n",
    "\n",
    "# Divide data (train, test)\n",
    "train_df, test_df = data_with_features.randomSplit([0.8, 0.2], seed=57)\n",
    "\n",
    "print(\"Original Dataset\")\n",
    "data_with_features.show(5)\n",
    "\n",
    "print(\"\\nTrain set\")\n",
    "train_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1601f5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/14 01:12:01 WARN DecisionTreeMetadata: DecisionTree reducing maxBins from 32 to 17 (= number of training instances)\n",
      "[Stage 1392:============================>                           (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Tree model summary:DecisionTreeClassificationModel: uid=DecisionTreeClassifier_eecd8e840088, depth=1, numNodes=3, numClasses=2, numFeatures=7\n",
      "  If (feature 0 <= 1016.0)\n",
      "   Predict: 0.0\n",
      "  Else (feature 0 > 1016.0)\n",
      "   Predict: 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "# Initialize and train the Decision Tree model\n",
    "dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "dt_model = dt.fit(train_df)\n",
    "\n",
    "# Display model summary\n",
    "print(\"\\nDecision Tree model summary:{0}\".format(dt_model.toDebugString))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a0bed238",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1396:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----------+\n",
      "|            features|label|prediction|\n",
      "+--------------------+-----+----------+\n",
      "|[188.0,5.0,0.0,52...|    0|       0.0|\n",
      "|[347.0,4.0,0.0,56...|    0|       0.0|\n",
      "|[348.0,5.0,0.0,94...|    0|       0.0|\n",
      "|[1001.0,4.0,0.0,9...|    0|       0.0|\n",
      "|[1837.0,4.0,0.0,6...|    1|       1.0|\n",
      "|[2028.0,0.0,0.0,6...|    1|       1.0|\n",
      "|[2399.0,0.0,0.0,3...|    1|       1.0|\n",
      "|[2428.0,1.0,0.0,2...|    1|       1.0|\n",
      "|[2837.0,2.0,0.0,8...|    1|       1.0|\n",
      "|[408.0,5.0,0.0,20...|    0|       0.0|\n",
      "|[1018.0,3.0,0.0,2...|    0|       1.0|\n",
      "|[1550.0,0.0,0.0,3...|    1|       1.0|\n",
      "|[2294.0,2.0,0.0,5...|    1|       1.0|\n",
      "|[2740.0,3.0,0.0,4...|    1|       1.0|\n",
      "|[2751.0,5.0,0.0,7...|    1|       1.0|\n",
      "|[2887.0,4.0,0.0,7...|    1|       1.0|\n",
      "+--------------------+-----+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = dt_model.transform(test_df)\n",
    "\n",
    "# Show predictions\n",
    "predictions.select(\"features\", \"label\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b9a4d97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9431818181818181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1403:============================>                           (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9361471861471862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\",\n",
    "                            predictionCol=\"prediction\")\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions, \n",
    "                  {evaluator.metricName: \"accuracy\"})\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "precision = evaluator.evaluate(predictions,\n",
    "                  {evaluator.metricName: \"weightedPrecision\"})\n",
    "print(f\"Precision: {precision}\")\n",
    "recall = evaluator.evaluate(predictions,\n",
    "                  {evaluator.metricName: \"weightedRecall\"})\n",
    "print(f\"Recall: {recall}\")\n",
    "f1 = evaluator.evaluate(predictions,\n",
    "                {evaluator.metricName: \"f1\"})\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8ea086ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----------+\n",
      "|            features|label|prediction|\n",
      "+--------------------+-----+----------+\n",
      "|[188.0,5.0,0.0,52...|    0|       0.0|\n",
      "|[347.0,4.0,0.0,56...|    0|       1.0|\n",
      "|[348.0,5.0,0.0,94...|    0|       0.0|\n",
      "|[1001.0,4.0,0.0,9...|    0|       1.0|\n",
      "|[1837.0,4.0,0.0,6...|    1|       1.0|\n",
      "+--------------------+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy Score (OneVsRest + LinearSVC): 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score (OneVsRest + LinearSVC): 0.8557692307692308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score (OneVsRest + LinearSVC): 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1494:============================>                           (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score (OneVsRest + LinearSVC): 0.7934782608695653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LinearSVC, OneVsRest\n",
    "\n",
    "# LinearSVC\n",
    "lsvc = LinearSVC(maxIter=10, regParam=0.1, labelCol=\"label\", featuresCol=\"features\")\n",
    "\n",
    "# OneVsRest\n",
    "ovr = OneVsRest(classifier=lsvc, labelCol=\"label\", featuresCol=\"features\")\n",
    "\n",
    "# Train model\n",
    "ovr_model = ovr.fit(train_df)\n",
    "\n",
    "# Make predictions\n",
    "ovr_predictions = ovr_model.transform(test_df)\n",
    "\n",
    "# Show predictions\n",
    "ovr_predictions.select(\"features\", \"label\", \"prediction\").show(5)\n",
    "\n",
    "# Evaluate model\n",
    "accuracy_ovr = evaluator.evaluate(ovr_predictions, {evaluator.metricName: \"accuracy\"})\n",
    "print(f\"\\nAccuracy Score (OneVsRest + LinearSVC): {accuracy_ovr}\")\n",
    "\n",
    "precision_ovr = evaluator.evaluate(ovr_predictions, {evaluator.metricName: \"weightedPrecision\"})\n",
    "print(f\"Precision Score (OneVsRest + LinearSVC): {precision_ovr}\")\n",
    "\n",
    "recall_ovr = evaluator.evaluate(ovr_predictions, {evaluator.metricName: \"weightedRecall\"})\n",
    "print(f\"Recall Score (OneVsRest + LinearSVC): {recall_ovr}\")\n",
    "\n",
    "f1_ovr = evaluator.evaluate(ovr_predictions, {evaluator.metricName: \"f1\"})\n",
    "print(f\"F1 Score (OneVsRest + LinearSVC): {f1_ovr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dde535e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc56a6a3",
   "metadata": {},
   "source": [
    "# 6. Conclusion\n",
    "\n",
    "## Main Achievements\n",
    "- Real-time recommendation system operational\n",
    "- Scalable data pipeline\n",
    "- Model with good accuracy metrics\n",
    "\n",
    "## Key Learnings\n",
    "1. Importance of preprocessing for streaming data\n",
    "2. Advantages of ALS for implicit feedback\n",
    "3. Challenges in the balance between coverage and diversity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
