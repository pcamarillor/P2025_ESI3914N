{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2718b337",
   "metadata": {},
   "source": [
    "# <center> <img src=\"../../labs/img/ITESOLogo.png\" alt=\"ITESO\" width=\"480\" height=\"130\"> </center>\n",
    "# <center> **Departamento de Electrónica, Sistemas e Informática** </center>\n",
    "---\n",
    "## <center> **Big Data** </center>\n",
    "---\n",
    "### <center> **Spring 2025** </center>\n",
    "---\n",
    "### <center> **Application: Video Streaming Analytics** </center>\n",
    "---\n",
    "#### <center> **Live monitoring of video quality, viewer behavior, and content recommendations from services like Netflix or YouTube.** </center>\n",
    "\n",
    "# <center> <img src=\"https://upload.wikimedia.org/wikipedia/commons/e/ef/Youtube_logo.png\" width=\"640\" height=\"443\"> </center>\n",
    "---\n",
    "**Profesor**: Dr. Pablo Camarillo Ramirez\n",
    "\n",
    "**Team members**: \n",
    "- Miguel Alberto Torres Dueñas\n",
    "- Juan Pablo Cortez Navarro\n",
    "- Luther Williams Sandria \n",
    "- Ferdinand Bierbaum\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c35d804",
   "metadata": {},
   "source": [
    "# 1. Introduction and Problem Definition\n",
    "\n",
    "## Project's Objective\n",
    "Develop a real-time recommendation system for a streaming platform that:\n",
    "- Analyze user behavior (viewing time, pauses, skips, etc.)\n",
    "- Generate personalized recommendations using machine learning\n",
    "- Scale to handle large volumes of data\n",
    "\n",
    "## App's Description\n",
    "Our solution implements:\n",
    "- **Data Ingestion**: Consuming real-time visualization events from Kafka\n",
    "- **Processing**: Data transformation and enrichment with PySpark\n",
    "- **Modeling**: ALS (Alternating Least Squares) based recommendation system\n",
    "- **Visualization**: Dashboard in PowerBI with key metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06c1af4",
   "metadata": {},
   "source": [
    "# 2. Arquitectura del Sistema\n",
    "\n",
    "pongan el esquema aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd3203d",
   "metadata": {},
   "source": [
    "# 3. Justificación de las 5V's del Big Data\n",
    "\n",
    "### Volume\n",
    "- **Estimación de Crecimiento**:\n",
    "  \n",
    "  |    Time Perriod  | Data Processed |\n",
    "  |------------------|----------------|\n",
    "  | 1 Second         | 500 KB         |\n",
    "  | 1 Minute (60s)   | 30 MB          |\n",
    "  | 1 Hour (3,600s)  | 1.8 GB         |\n",
    "  | 1 Day (86,400s)  | 43.2 GB        |\n",
    "  | 1 Year (31.5M s) | 15.7 TB        |\n",
    "\n",
    "\n",
    "- **Management Strategies**:\n",
    "  - Data Partitioning in Parquet\n",
    "  - Distributed processing with Spark\n",
    "  - Schema optimization (appropriate data types)\n",
    "\n",
    "### Velocity\n",
    "- **Performance Metrics**:\n",
    "  - `processedRowsPerSecond`: X rows/second\n",
    "  - Latencia end-to-end: < X seconds for recommendations\n",
    "- **Techniques Implemented**:\n",
    "  - Structured Streaming with triggers each 3 seconds\n",
    "  - Checkpointing to ensure exactly-one-processing\n",
    "\n",
    "### Variety\n",
    "- **Data Schema**:\n",
    "```python\n",
    "root\n",
    " |-- user_id: string (nullable = true)\n",
    " |-- video_id: string (nullable = true)\n",
    " |-- watch_time_seconds: double (nullable = true)\n",
    " |-- resolution: string (nullable = true)\n",
    " |-- buffering_events: integer (nullable = true)\n",
    " |-- paused: boolean (nullable = true)\n",
    " |-- skipped: boolean (nullable = true)\n",
    " |-- genre: string (nullable = true)\n",
    " |-- timestamp: timestamp (nullable = true)\n",
    "```\n",
    "\n",
    "### Veracity\n",
    "- Schema validation when ingesting data\n",
    "- Filtering incomplete records\n",
    "- Quality metrics in PowerBI\n",
    "\n",
    "### Value\n",
    "- watch_time_seconds: User engagement\n",
    "- buffering_events: Quality of Experience\n",
    "- genre: Personal preferences\n",
    "- skipped: Non-relevant content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2a9313",
   "metadata": {},
   "source": [
    "# 4. Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ce40fc",
   "metadata": {},
   "source": [
    "## Spark Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c8e960f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "#0be7b65b50a239d7ee8b621f3c329b25c5c4aadafbae5ac7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e808d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/conda/spark-3.5.4-bin-hadoop3-scala2.13/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "org.apache.spark#spark-sql-kafka-0-10_2.13 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-623098f2-4ccb-476c-9d0a-aa1fbbe72475;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.spark#spark-sql-kafka-0-10_2.13;3.5.4 in central\n",
      "\tfound org.apache.spark#spark-token-provider-kafka-0-10_2.13;3.5.4 in central\n",
      "\tfound org.apache.kafka#kafka-clients;3.4.1 in central\n",
      "\tfound org.lz4#lz4-java;1.8.0 in central\n",
      "\tfound org.xerial.snappy#snappy-java;1.1.10.5 in central\n",
      "\tfound org.slf4j#slf4j-api;2.0.7 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-runtime;3.3.4 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-api;3.3.4 in central\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.0 in central\n",
      "\tfound org.scala-lang.modules#scala-parallel-collections_2.13;1.0.4 in central\n",
      "\tfound org.apache.commons#commons-pool2;2.11.1 in central\n",
      ":: resolution report :: resolve 710ms :: artifacts dl 26ms\n",
      "\t:: modules in use:\n",
      "\tcom.google.code.findbugs#jsr305;3.0.0 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\torg.apache.commons#commons-pool2;2.11.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-api;3.3.4 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-runtime;3.3.4 from central in [default]\n",
      "\torg.apache.kafka#kafka-clients;3.4.1 from central in [default]\n",
      "\torg.apache.spark#spark-sql-kafka-0-10_2.13;3.5.4 from central in [default]\n",
      "\torg.apache.spark#spark-token-provider-kafka-0-10_2.13;3.5.4 from central in [default]\n",
      "\torg.lz4#lz4-java;1.8.0 from central in [default]\n",
      "\torg.scala-lang.modules#scala-parallel-collections_2.13;1.0.4 from central in [default]\n",
      "\torg.slf4j#slf4j-api;2.0.7 from central in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.10.5 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   12  |   0   |   0   |   0   ||   12  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-623098f2-4ccb-476c-9d0a-aa1fbbe72475\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 12 already retrieved (0kB/22ms)\n",
      "25/05/14 01:44:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SparkSQLStructuredStreaming-Kafka\") \\\n",
    "    .master(\"spark://7a8106b8550d:7077\") \\\n",
    "    .config(\"spark.ui.port\",\"4040\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.13:3.5.4\") \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3549704a",
   "metadata": {},
   "source": [
    "## Kafka Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc4d173b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: binary (nullable = true)\n",
      " |-- value: binary (nullable = true)\n",
      " |-- topic: string (nullable = true)\n",
      " |-- partition: integer (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- timestampType: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kafka_lines = spark \\\n",
    "                .readStream \\\n",
    "                .format(\"kafka\") \\\n",
    "                .option(\"kafka.bootstrap.servers\", \"ed69dac0a4e4:9093\") \\\n",
    "                .option(\"subscribe\", \"kafka-spark-example-0\") \\\n",
    "                .option(\"subscribe\", \"kafka-spark-example-1\") \\\n",
    "                .option(\"subscribe\", \"kafka-spark-example-2\") \\\n",
    "                .option(\"subscribe\", \"kafka-spark-example-3\") \\\n",
    "                .load()\n",
    "\n",
    "kafka_lines.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cd106a",
   "metadata": {},
   "source": [
    "## Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e9101b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- pairs_array: array (nullable = true)\n",
      " |    |-- element: string (containsNull = false)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- video_id: string (nullable = true)\n",
      " |-- watch_time_seconds: string (nullable = true)\n",
      " |-- resolution: string (nullable = true)\n",
      " |-- bitrate_kbps: string (nullable = true)\n",
      " |-- buffering_events: string (nullable = true)\n",
      " |-- paused: string (nullable = true)\n",
      " |-- skipped: string (nullable = true)\n",
      " |-- genre: string (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      " |-- recommended: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import split, col, expr\n",
    "\n",
    "kafka_df = kafka_lines.select(split(col(\"value\"), \",\").alias(\"pairs_array\"))\n",
    "\n",
    "kafka_df = kafka_df.withColumn(\"user_id\", split(col(\"pairs_array\").getItem(0), \":\").getItem(1))\n",
    "kafka_df = kafka_df.withColumn(\"video_id\", split(col(\"pairs_array\").getItem(1), \":\").getItem(1))\n",
    "kafka_df = kafka_df.withColumn(\"watch_time_seconds\", split(col(\"pairs_array\").getItem(2), \":\").getItem(1))\n",
    "kafka_df = kafka_df.withColumn(\"resolution\", split(col(\"pairs_array\").getItem(3), \":\").getItem(1))\n",
    "kafka_df = kafka_df.withColumn(\"bitrate_kbps\", split(col(\"pairs_array\").getItem(4), \":\").getItem(1))\n",
    "kafka_df = kafka_df.withColumn(\"buffering_events\", split(col(\"pairs_array\").getItem(5), \":\").getItem(1))\n",
    "kafka_df = kafka_df.withColumn(\"paused\", split(col(\"pairs_array\").getItem(6), \":\").getItem(1))\n",
    "kafka_df = kafka_df.withColumn(\"skipped\", split(col(\"pairs_array\").getItem(7), \":\").getItem(1))\n",
    "kafka_df = kafka_df.withColumn(\"genre\", split(col(\"pairs_array\").getItem(8), \":\").getItem(1))\n",
    "kafka_df = kafka_df.withColumn(\"region\", split(col(\"pairs_array\").getItem(9), \":\").getItem(1))\n",
    "kafka_df = kafka_df.withColumn(\"recommended\", split(col(\"pairs_array\").getItem(10), \":\").getItem(1))\n",
    "\n",
    "# Usamos expr para hacer la resta de longitud directamente\n",
    "kafka_df = kafka_df.withColumn(\n",
    "    \"timestamp\",\n",
    "    expr(\"substring(split(pairs_array[11], ':')[1], 1, length(split(pairs_array[11], ':')[1]) - 1)\")\n",
    ")\n",
    "\n",
    "kafka_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c63df52",
   "metadata": {},
   "source": [
    "## Streaming processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8b97666",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/14 01:45:23 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n",
      "25/05/14 01:45:24 WARN AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.\n",
      "25/05/14 01:45:27 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000 milliseconds, but spent 3477 milliseconds\n",
      "25/05/14 01:49:45 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 3000 milliseconds, but spent 3045 milliseconds\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "query_files = kafka_df \\\n",
    "                .writeStream \\\n",
    "                .outputMode(\"append\") \\\n",
    "                .trigger(processingTime='3 seconds') \\\n",
    "                .format(\"parquet\") \\\n",
    "                .option(\"path\", \"/home/jovyan/notebooks/data/project_parquet\") \\\n",
    "                .option(\"truncate\", \"false\") \\\n",
    "                .option(\"checkpointLocation\", \"/home/jovyan/checkpoint\") \\\n",
    "                .start()\n",
    "query_files.awaitTermination(300)\n",
    "query_files.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62d10ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 99:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+----------+------------------+----------+------------+----------------+------+-------+--------------+------+-----------+-------------+\n",
      "|         pairs_array|     user_id|  video_id|watch_time_seconds|resolution|bitrate_kbps|buffering_events|paused|skipped|         genre|region|recommended|    timestamp|\n",
      "+--------------------+------------+----------+------------------+----------+------------+----------------+------+-------+--------------+------+-----------+-------------+\n",
      "|[{\"user_id\": \"use...| \"user_8368\"| \"vid_012\"|              1457|      \"4K\"|        7844|               1| false|   true| \"Documentary\"|  \"JP\"|      false| \"05/14/2025\"|\n",
      "|[{\"user_id\": \"use...| \"user_6418\"| \"vid_098\"|              2824|    \"480p\"|        2782|               2| false|   true| \"Documentary\"|  \"IN\"|      false| \"05/14/2025\"|\n",
      "|[{\"user_id\": \"use...| \"user_6449\"| \"vid_076\"|               468|    \"480p\"|        5801|               2| false|   true|       \"Drama\"|  \"JP\"|      false| \"05/14/2025\"|\n",
      "|[{\"user_id\": \"use...| \"user_8287\"| \"vid_065\"|              1849|    \"480p\"|        5811|               1|  true|   true| \"Documentary\"|  \"JP\"|      false| \"05/14/2025\"|\n",
      "|[{\"user_id\": \"use...| \"user_6434\"| \"vid_048\"|              2954|    \"480p\"|        1214|               2| false|  false|      \"Comedy\"|  \"UK\"|      false| \"05/14/2025\"|\n",
      "|[{\"user_id\": \"use...| \"user_2636\"| \"vid_018\"|              1413|    \"480p\"|        7618|               2|  true|  false|      \"Sci-Fi\"|  \"DE\"|      false| \"05/14/2025\"|\n",
      "|[{\"user_id\": \"use...| \"user_6822\"| \"vid_091\"|               191|   \"1080p\"|        2732|               2| false|  false| \"Documentary\"|  \"IN\"|       true| \"05/14/2025\"|\n",
      "|[{\"user_id\": \"use...| \"user_1606\"| \"vid_064\"|              2359|    \"720p\"|        4775|               2| false|  false|      \"Sci-Fi\"|  \"BR\"|      false| \"05/14/2025\"|\n",
      "|[{\"user_id\": \"use...| \"user_6554\"| \"vid_074\"|              2112|    \"480p\"|        6530|               4| false|   true|       \"Drama\"|  \"US\"|       true| \"05/14/2025\"|\n",
      "|[{\"user_id\": \"use...| \"user_5139\"| \"vid_030\"|              3364|    \"480p\"|        7309|               2|  true|   true| \"Documentary\"|  \"IN\"|       true| \"05/14/2025\"|\n",
      "|[{\"user_id\": \"use...| \"user_4556\"| \"vid_078\"|              1258|    \"720p\"|        6155|               5| false|  false|      \"Comedy\"|  \"MX\"|      false| \"05/14/2025\"|\n",
      "|[{\"user_id\": \"use...| \"user_5506\"| \"vid_010\"|              1239|      \"4K\"|        3439|               4| false|  false| \"Documentary\"|  \"BR\"|      false| \"05/14/2025\"|\n",
      "|[{\"user_id\": \"use...| \"user_1747\"| \"vid_075\"|              1155|   \"1080p\"|        2299|               3|  true|  false|      \"Comedy\"|  \"BR\"|      false| \"05/14/2025\"|\n",
      "|[{\"user_id\": \"use...| \"user_7599\"| \"vid_071\"|              2121|    \"480p\"|        3278|               4| false|  false|      \"Comedy\"|  \"IN\"|      false| \"05/14/2025\"|\n",
      "|[{\"user_id\": \"use...| \"user_1197\"| \"vid_080\"|               772|    \"480p\"|        1745|               1| false|  false|      \"Comedy\"|  \"MX\"|      false| \"05/14/2025\"|\n",
      "|[{\"user_id\": \"use...| \"user_2150\"| \"vid_027\"|              2050|   \"1080p\"|        1238|               4| false|  false|      \"Action\"|  \"UK\"|      false| \"05/14/2025\"|\n",
      "|[{\"user_id\": \"use...| \"user_8584\"| \"vid_071\"|               586|    \"720p\"|        4608|               1| false|   true|      \"Horror\"|  \"MX\"|      false| \"05/14/2025\"|\n",
      "|[{\"user_id\": \"use...| \"user_8125\"| \"vid_008\"|               193|    \"720p\"|        7737|               5| false|  false|      \"Sci-Fi\"|  \"IN\"|      false| \"05/14/2025\"|\n",
      "|[{\"user_id\": \"use...| \"user_2016\"| \"vid_015\"|               669|    \"480p\"|        3940|               5| false|   true|      \"Comedy\"|  \"UK\"|       true| \"05/14/2025\"|\n",
      "|[{\"user_id\": \"use...| \"user_5477\"| \"vid_047\"|              2133|      \"4K\"|        1292|               4|  true|   true|      \"Comedy\"|  \"IN\"|       true| \"05/14/2025\"|\n",
      "+--------------------+------------+----------+------------------+----------+------------+----------------+------+-------+--------------+------+-----------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(\"/home/jovyan/notebooks/data/project_parquet\")\n",
    "df.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf5de13",
   "metadata": {},
   "source": [
    "## Machine Learning Model - ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33e7d5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+-------------------+\n",
      "|user_id_int|video_id_int|  implicit_feedback|\n",
      "+-----------+------------+-------------------+\n",
      "|       8368|          12| 0.6128333333333333|\n",
      "|       6418|          98| 0.8106666666666666|\n",
      "|       6449|          76|0.41800000000000004|\n",
      "|       8287|          65| 0.6781666666666667|\n",
      "|       6434|          48| 0.8323333333333333|\n",
      "+-----------+------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, regexp_extract, when\n",
    "\n",
    "# Leer datos Parquet\n",
    "video_data = spark.read.parquet(\"/home/jovyan/notebooks/data/project_parquet\")\n",
    "\n",
    "# Convertir tipos de datos correctamente\n",
    "video_data = video_data.withColumn(\"watch_time_seconds\", col(\"watch_time_seconds\").cast(\"double\")) \\\n",
    "                      .withColumn(\"buffering_events\", col(\"buffering_events\").cast(\"double\")) \\\n",
    "                      .withColumn(\"skipped\", when(col(\"skipped\") == \"true\", 1).otherwise(0))\n",
    "\n",
    "# Crear IDs numéricos (como lo tienes)\n",
    "video_data = video_data.withColumn(\"user_id_int\", regexp_extract(col(\"user_id\"), \"user_(\\\\d+)\", 1).cast(\"integer\")) \\\n",
    "                      .withColumn(\"video_id_int\", regexp_extract(col(\"video_id\"), \"vid_(\\\\d+)\", 1).cast(\"integer\"))\n",
    "\n",
    "# Crear métrica de feedback implícito (versión corregida)\n",
    "video_data = video_data.withColumn(\"implicit_feedback\", \n",
    "                                 (col(\"watch_time_seconds\")/3600 * 0.6 +  # Tiempo de visualización en horas\n",
    "                                  (1 - col(\"buffering_events\")/10) * 0.3 +  # Inverso de buffering\n",
    "                                  (1 - col(\"skipped\")) * 0.1))  # No saltado\n",
    "\n",
    "# Verificar datos\n",
    "video_data.select(\"user_id_int\", \"video_id_int\", \"implicit_feedback\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08e5c6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "als = ALS(\n",
    "    userCol=\"user_id_int\",\n",
    "    itemCol=\"video_id_int\",\n",
    "    ratingCol=\"implicit_feedback\",\n",
    "    implicitPrefs=True,  # Usar feedback implícito\n",
    "    coldStartStrategy=\"drop\",  # Manejar nuevos usuarios/videos\n",
    "    nonnegative=True,  # Solo factores positivos\n",
    "    rank=10,  # Factores latentes (ajustable)\n",
    "    maxIter=15,  # Iteraciones (ajustable)\n",
    "    regParam=0.1  # Regularización (ajustable)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c94e214c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/14 01:52:16 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "25/05/14 01:52:16 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n"
     ]
    }
   ],
   "source": [
    "# Entrenar modelo\n",
    "model = als.fit(video_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dec19eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recomendaciones para usuarios de ejemplo:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------------------------------------------------------------------------------------------+\n",
      "|user_id_int|recommendations                                                                                     |\n",
      "+-----------+----------------------------------------------------------------------------------------------------+\n",
      "|1001       |[{30, 0.015387675}, {42, 0.010473358}, {98, 0.005360664}, {18, 0.0031405862}, {54, 0.002868512}]    |\n",
      "|1010       |[{71, 0.48284122}, {94, 0.48276308}, {48, 0.2808086}, {41, 0.008239763}, {32, 0.003128767}]         |\n",
      "|1014       |[{64, 0.40260407}, {13, 0.39644858}, {84, 0.32852596}, {75, 0.19948319}, {8, 0.18014888}]           |\n",
      "|1164       |[{53, 0.49065003}, {12, 0.47440022}, {36, 0.30805808}, {72, 0.16130526}, {46, 0.11950746}]          |\n",
      "|1197       |[{53, 2.3021398E-6}, {12, 2.2259153E-6}, {36, 1.4454278E-6}, {72, 7.568543E-7}, {46, 5.6073645E-7}] |\n",
      "|1289       |[{18, 0.58774525}, {54, 0.53682786}, {41, 0.34775618}, {92, 0.055502586}, {50, 0.009764949}]        |\n",
      "|1414       |[{18, 0.51784986}, {54, 0.47298762}, {41, 0.30640057}, {92, 0.048902147}, {50, 0.008603688}]        |\n",
      "|1598       |[{26, 0.43082052}, {37, 0.42614552}, {15, 0.42599195}, {50, 0.0036389774}, {53, 9.0849673E-4}]      |\n",
      "|1606       |[{64, 0.4218133}, {13, 0.41535363}, {84, 0.34419206}, {75, 0.20899574}, {8, 0.18873946}]            |\n",
      "|1677       |[{18, 1.2525059E-4}, {54, 1.14399925E-4}, {41, 7.410807E-5}, {92, 1.1827798E-5}, {26, 6.9591783E-6}]|\n",
      "|1747       |[{64, 0.2127578}, {13, 0.2095049}, {84, 0.17361091}, {75, 0.10541772}, {8, 0.09520043}]             |\n",
      "|1881       |[{65, 0.033042002}, {53, 0.031417504}, {12, 0.03037726}, {36, 0.019725878}, {59, 0.018059539}]      |\n",
      "|1882       |[{71, 0.55056655}, {94, 0.55047745}, {48, 0.32019597}, {41, 0.009395505}, {32, 0.0035676209}]       |\n",
      "|1952       |[{53, 4.0454208E-4}, {12, 3.911476E-4}, {30, 3.0565853E-4}, {36, 2.539969E-4}, {42, 2.0804127E-4}]  |\n",
      "|2016       |[{26, 0.37940264}, {37, 0.3752856}, {15, 0.37515035}, {50, 0.00320467}, {53, 8.000688E-4}]          |\n",
      "|2031       |[{30, 0.7033585}, {42, 0.47872895}, {98, 0.24503171}, {9, 0.01247489}, {83, 0.0076894774}]          |\n",
      "|2150       |[{64, 0.096900605}, {13, 0.09541907}, {84, 0.07907115}, {75, 0.048012536}, {8, 0.043359064}]        |\n",
      "|2196       |[{65, 0.4651568}, {59, 0.25423753}, {49, 0.2540098}, {74, 0.14388677}, {55, 0.020245586}]           |\n",
      "|2257       |[{64, 0.023309402}, {13, 0.022953019}, {84, 0.019020531}, {75, 0.0115493955}, {8, 0.010430005}]     |\n",
      "|2292       |[{18, 0.41144073}, {54, 0.3757969}, {41, 0.24361901}, {92, 0.038853608}, {71, 0.00946011}]          |\n",
      "+-----------+----------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "\n",
      "Top 5 recomendaciones para usuario 8072:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 833:>                                                        (0 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+\n",
      "|user_id_int|recommendations|\n",
      "+-----------+---------------+\n",
      "+-----------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Recomendaciones para todos los usuarios (top 10)\n",
    "user_recs = model.recommendForAllUsers(5)\n",
    "\n",
    "# Mostrar recomendaciones para algunos usuarios\n",
    "print(\"Recomendaciones para usuarios de ejemplo:\")\n",
    "user_recs.show(truncate=False)\n",
    "\n",
    "# Recomendaciones para un usuario específico\n",
    "user_id_ejemplo = 8072\n",
    "recs_usuario = model.recommendForUserSubset(\n",
    "    spark.createDataFrame([(user_id_ejemplo,)]).toDF(\"user_id_int\"), \n",
    "    5\n",
    ")\n",
    "print(f\"\\nTop 5 recomendaciones para usuario {user_id_ejemplo}:\")\n",
    "recs_usuario.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf2a8688",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+----------+------------------+----------+------------+----------------+------+-------+--------------+------+-----------+-------------+-----------+------------+-------------------+-------------+\n",
      "|pairs_array                                                                                                                                                                                                                                                                            |user_id     |video_id  |watch_time_seconds|resolution|bitrate_kbps|buffering_events|paused|skipped|genre         |region|recommended|timestamp    |user_id_int|video_id_int|implicit_feedback  |prediction   |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+----------+------------------+----------+------------+----------------+------+-------+--------------+------+-----------+-------------+-----------+------------+-------------------+-------------+\n",
      "|[{\"user_id\": \"user_3986\",  \"video_id\": \"vid_016\",  \"watch_time_seconds\": 3132,  \"resolution\": \"1080p\",  \"bitrate_kbps\": 4456,  \"buffering_events\": 0,  \"paused\": false,  \"skipped\": false,  \"genre\": \"Documentary\",  \"region\": \"BR\",  \"recommended\": true,  \"timestamp\": \"05/14/2025\"}]| \"user_3986\"| \"vid_016\"|3132.0            | \"1080p\"  | 4456       |0.0             | false|0      | \"Documentary\"| \"BR\" | true      | \"05/14/2025\"|3986       |16          |0.922              |0.5285562    |\n",
      "|[{\"user_id\": \"user_8640\",  \"video_id\": \"vid_099\",  \"watch_time_seconds\": 1982,  \"resolution\": \"720p\",  \"bitrate_kbps\": 6962,  \"buffering_events\": 5,  \"paused\": true,  \"skipped\": false,  \"genre\": \"Sci-Fi\",  \"region\": \"US\",  \"recommended\": true,  \"timestamp\": \"05/14/2025\"}]       | \"user_8640\"| \"vid_099\"|1982.0            | \"720p\"   | 6962       |5.0             | true |0      | \"Sci-Fi\"     | \"US\" | true      | \"05/14/2025\"|8640       |99          |0.5803333333333333 |0.16309315   |\n",
      "|[{\"user_id\": \"user_5920\",  \"video_id\": \"vid_038\",  \"watch_time_seconds\": 2633,  \"resolution\": \"4K\",  \"bitrate_kbps\": 5880,  \"buffering_events\": 1,  \"paused\": false,  \"skipped\": false,  \"genre\": \"Documentary\",  \"region\": \"UK\",  \"recommended\": true,  \"timestamp\": \"05/14/2025\"}]   | \"user_5920\"| \"vid_038\"|2633.0            | \"4K\"     | 5880       |1.0             | false|0      | \"Documentary\"| \"UK\" | true      | \"05/14/2025\"|5920       |38          |0.8088333333333333 |0.4612426    |\n",
      "|[{\"user_id\": \"user_7599\",  \"video_id\": \"vid_071\",  \"watch_time_seconds\": 2121,  \"resolution\": \"480p\",  \"bitrate_kbps\": 3278,  \"buffering_events\": 4,  \"paused\": false,  \"skipped\": false,  \"genre\": \"Comedy\",  \"region\": \"IN\",  \"recommended\": false,  \"timestamp\": \"05/14/2025\"}]     | \"user_7599\"| \"vid_071\"|2121.0            | \"480p\"   | 3278       |4.0             | false|0      | \"Comedy\"     | \"IN\" | false     | \"05/14/2025\"|7599       |71          |0.6335             |0.51466924   |\n",
      "|[{\"user_id\": \"user_7192\",  \"video_id\": \"vid_077\",  \"watch_time_seconds\": 890,  \"resolution\": \"4K\",  \"bitrate_kbps\": 6218,  \"buffering_events\": 0,  \"paused\": false,  \"skipped\": true,  \"genre\": \"Drama\",  \"region\": \"JP\",  \"recommended\": true,  \"timestamp\": \"05/14/2025\"}]           | \"user_7192\"| \"vid_077\"|890.0             | \"4K\"     | 6218       |0.0             | false|0      | \"Drama\"      | \"JP\" | true      | \"05/14/2025\"|7192       |77          |0.5483333333333333 |2.1553783E-12|\n",
      "|[{\"user_id\": \"user_6509\",  \"video_id\": \"vid_054\",  \"watch_time_seconds\": 144,  \"resolution\": \"480p\",  \"bitrate_kbps\": 3981,  \"buffering_events\": 4,  \"paused\": true,  \"skipped\": false,  \"genre\": \"Horror\",  \"region\": \"IN\",  \"recommended\": true,  \"timestamp\": \"05/14/2025\"}]        | \"user_6509\"| \"vid_054\"|144.0             | \"480p\"   | 3981       |4.0             | true |0      | \"Horror\"     | \"IN\" | true      | \"05/14/2025\"|6509       |54          |0.304              |0.41381174   |\n",
      "|[{\"user_id\": \"user_7290\",  \"video_id\": \"vid_091\",  \"watch_time_seconds\": 931,  \"resolution\": \"720p\",  \"bitrate_kbps\": 7473,  \"buffering_events\": 4,  \"paused\": false,  \"skipped\": true,  \"genre\": \"Horror\",  \"region\": \"JP\",  \"recommended\": false,  \"timestamp\": \"05/14/2025\"}]       | \"user_7290\"| \"vid_091\"|931.0             | \"720p\"   | 7473       |4.0             | false|0      | \"Horror\"     | \"JP\" | false     | \"05/14/2025\"|7290       |91          |0.4351666666666667 |5.452454E-5  |\n",
      "|[{\"user_id\": \"user_3972\",  \"video_id\": \"vid_026\",  \"watch_time_seconds\": 241,  \"resolution\": \"480p\",  \"bitrate_kbps\": 4575,  \"buffering_events\": 1,  \"paused\": false,  \"skipped\": true,  \"genre\": \"Sci-Fi\",  \"region\": \"IN\",  \"recommended\": true,  \"timestamp\": \"05/14/2025\"}]        | \"user_3972\"| \"vid_026\"|241.0             | \"480p\"   | 4575       |1.0             | false|0      | \"Sci-Fi\"     | \"IN\" | true      | \"05/14/2025\"|3972       |26          |0.4101666666666667 |0.3911653    |\n",
      "|[{\"user_id\": \"user_8287\",  \"video_id\": \"vid_065\",  \"watch_time_seconds\": 1849,  \"resolution\": \"480p\",  \"bitrate_kbps\": 5811,  \"buffering_events\": 1,  \"paused\": true,  \"skipped\": true,  \"genre\": \"Documentary\",  \"region\": \"JP\",  \"recommended\": false,  \"timestamp\": \"05/14/2025\"}]  | \"user_8287\"| \"vid_065\"|1849.0            | \"480p\"   | 5811       |1.0             | true |0      | \"Documentary\"| \"JP\" | false     | \"05/14/2025\"|8287       |65          |0.6781666666666667 |0.66601133   |\n",
      "|[{\"user_id\": \"user_2031\",  \"video_id\": \"vid_030\",  \"watch_time_seconds\": 2611,  \"resolution\": \"720p\",  \"bitrate_kbps\": 1105,  \"buffering_events\": 4,  \"paused\": false,  \"skipped\": true,  \"genre\": \"Sci-Fi\",  \"region\": \"BR\",  \"recommended\": false,  \"timestamp\": \"05/14/2025\"}]      | \"user_2031\"| \"vid_030\"|2611.0            | \"720p\"   | 1105       |4.0             | false|0      | \"Sci-Fi\"     | \"BR\" | false     | \"05/14/2025\"|2031       |30          |0.7151666666666666 |0.7033585    |\n",
      "|[{\"user_id\": \"user_4336\",  \"video_id\": \"vid_016\",  \"watch_time_seconds\": 1358,  \"resolution\": \"1080p\",  \"bitrate_kbps\": 7072,  \"buffering_events\": 3,  \"paused\": false,  \"skipped\": true,  \"genre\": \"Horror\",  \"region\": \"BR\",  \"recommended\": true,  \"timestamp\": \"05/14/2025\"}]      | \"user_4336\"| \"vid_016\"|1358.0            | \"1080p\"  | 7072       |3.0             | false|0      | \"Horror\"     | \"BR\" | true      | \"05/14/2025\"|4336       |16          |0.5363333333333333 |0.76520616   |\n",
      "|[{\"user_id\": \"user_4336\",  \"video_id\": \"vid_056\",  \"watch_time_seconds\": 3098,  \"resolution\": \"4K\",  \"bitrate_kbps\": 3872,  \"buffering_events\": 2,  \"paused\": true,  \"skipped\": true,  \"genre\": \"Documentary\",  \"region\": \"IN\",  \"recommended\": false,  \"timestamp\": \"05/14/2025\"}]    | \"user_4336\"| \"vid_056\"|3098.0            | \"4K\"     | 3872       |2.0             | true |0      | \"Documentary\"| \"IN\" | false     | \"05/14/2025\"|4336       |56          |0.8563333333333333 |0.6272696    |\n",
      "|[{\"user_id\": \"user_1197\",  \"video_id\": \"vid_080\",  \"watch_time_seconds\": 772,  \"resolution\": \"480p\",  \"bitrate_kbps\": 1745,  \"buffering_events\": 1,  \"paused\": false,  \"skipped\": false,  \"genre\": \"Comedy\",  \"region\": \"MX\",  \"recommended\": false,  \"timestamp\": \"05/14/2025\"}]      | \"user_1197\"| \"vid_080\"|772.0             | \"480p\"   | 1745       |1.0             | false|0      | \"Comedy\"     | \"MX\" | false     | \"05/14/2025\"|1197       |80          |0.4986666666666667 |9.691124E-12 |\n",
      "|[{\"user_id\": \"user_8523\",  \"video_id\": \"vid_096\",  \"watch_time_seconds\": 268,  \"resolution\": \"480p\",  \"bitrate_kbps\": 5991,  \"buffering_events\": 2,  \"paused\": true,  \"skipped\": true,  \"genre\": \"Documentary\",  \"region\": \"JP\",  \"recommended\": false,  \"timestamp\": \"05/14/2025\"}]   | \"user_8523\"| \"vid_096\"|268.0             | \"480p\"   | 5991       |2.0             | true |0      | \"Documentary\"| \"JP\" | false     | \"05/14/2025\"|8523       |96          |0.3846666666666666 |3.7313468E-5 |\n",
      "|[{\"user_id\": \"user_2781\",  \"video_id\": \"vid_042\",  \"watch_time_seconds\": 1815,  \"resolution\": \"4K\",  \"bitrate_kbps\": 3874,  \"buffering_events\": 5,  \"paused\": false,  \"skipped\": false,  \"genre\": \"Documentary\",  \"region\": \"US\",  \"recommended\": false,  \"timestamp\": \"05/14/2025\"}]  | \"user_2781\"| \"vid_042\"|1815.0            | \"4K\"     | 3874       |5.0             | false|0      | \"Documentary\"| \"US\" | false     | \"05/14/2025\"|2781       |42          |0.5525             |0.36336306   |\n",
      "|[{\"user_id\": \"user_9493\",  \"video_id\": \"vid_037\",  \"watch_time_seconds\": 3346,  \"resolution\": \"480p\",  \"bitrate_kbps\": 5127,  \"buffering_events\": 0,  \"paused\": false,  \"skipped\": true,  \"genre\": \"Drama\",  \"region\": \"IN\",  \"recommended\": true,  \"timestamp\": \"05/14/2025\"}]        | \"user_9493\"| \"vid_037\"|3346.0            | \"480p\"   | 5127       |0.0             | false|0      | \"Drama\"      | \"IN\" | true      | \"05/14/2025\"|9493       |37          |0.9576666666666666 |0.4635699    |\n",
      "|[{\"user_id\": \"user_7217\",  \"video_id\": \"vid_043\",  \"watch_time_seconds\": 3208,  \"resolution\": \"1080p\",  \"bitrate_kbps\": 7349,  \"buffering_events\": 1,  \"paused\": true,  \"skipped\": true,  \"genre\": \"Drama\",  \"region\": \"IN\",  \"recommended\": false,  \"timestamp\": \"05/14/2025\"}]       | \"user_7217\"| \"vid_043\"|3208.0            | \"1080p\"  | 7349       |1.0             | true |0      | \"Drama\"      | \"IN\" | false     | \"05/14/2025\"|7217       |43          |0.9046666666666666 |1.0490057E-5 |\n",
      "|[{\"user_id\": \"user_4991\",  \"video_id\": \"vid_058\",  \"watch_time_seconds\": 2371,  \"resolution\": \"4K\",  \"bitrate_kbps\": 6865,  \"buffering_events\": 3,  \"paused\": true,  \"skipped\": true,  \"genre\": \"Horror\",  \"region\": \"JP\",  \"recommended\": true,  \"timestamp\": \"05/14/2025\"}]          | \"user_4991\"| \"vid_058\"|2371.0            | \"4K\"     | 6865       |3.0             | true |0      | \"Horror\"     | \"JP\" | true      | \"05/14/2025\"|4991       |58          |0.7051666666666666 |4.7242313E-8 |\n",
      "|[{\"user_id\": \"user_4620\",  \"video_id\": \"vid_004\",  \"watch_time_seconds\": 3273,  \"resolution\": \"480p\",  \"bitrate_kbps\": 4013,  \"buffering_events\": 1,  \"paused\": true,  \"skipped\": false,  \"genre\": \"Horror\",  \"region\": \"IN\",  \"recommended\": true,  \"timestamp\": \"05/14/2025\"}]       | \"user_4620\"| \"vid_004\"|3273.0            | \"480p\"   | 4013       |1.0             | true |0      | \"Horror\"     | \"IN\" | true      | \"05/14/2025\"|4620       |4           |0.9155             |0.06629185   |\n",
      "|[{\"user_id\": \"user_7559\",  \"video_id\": \"vid_027\",  \"watch_time_seconds\": 1039,  \"resolution\": \"720p\",  \"bitrate_kbps\": 3246,  \"buffering_events\": 3,  \"paused\": true,  \"skipped\": true,  \"genre\": \"Horror\",  \"region\": \"US\",  \"recommended\": true,  \"timestamp\": \"05/14/2025\"}]        | \"user_7559\"| \"vid_027\"|1039.0            | \"720p\"   | 3246       |3.0             | true |0      | \"Horror\"     | \"US\" | true      | \"05/14/2025\"|7559       |27          |0.48316666666666663|0.018086305  |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+----------+------------------+----------+------------+----------------+------+-------+--------------+------+-----------+-------------+-----------+------------+-------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Hacer predicciones\n",
    "predictions = model.transform(video_data)\n",
    "predictions.show(truncate=False)\n",
    "\n",
    "# CSV\n",
    "predictions_for_bi = predictions.select(\n",
    "    col(\"user_id\"),                    \n",
    "    col(\"video_id\"),                   \n",
    "    col(\"user_id_int\"),                \n",
    "    col(\"video_id_int\"),               \n",
    "    col(\"watch_time_seconds\"),         \n",
    "    col(\"resolution\"),                 \n",
    "    col(\"genre\"),                      \n",
    "    col(\"region\"),                     \n",
    "    col(\"recommended\"),                \n",
    "    col(\"implicit_feedback\"),  \n",
    "    col(\"prediction\"),        \n",
    "    col(\"timestamp\")                   \n",
    ")\n",
    "\n",
    "predictions_for_bi.coalesce(1) \\\n",
    "    .write \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"delimiter\", \",\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .csv(\"/home/jovyan/notebooks/data/project_parquet/output/csv_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b74dc8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RMSE del modelo: 0.44541768418542316\n"
     ]
    }
   ],
   "source": [
    "# Evaluar con RMSE\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\",\n",
    "    labelCol=\"implicit_feedback\",\n",
    "    predictionCol=\"prediction\"\n",
    ")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"\\nRMSE del modelo: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3115aa7c",
   "metadata": {},
   "source": [
    "# 5. Results and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a85d78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "\n",
    "# Prepare data\n",
    "video_data = video_data.withColumn(\"label\", \n",
    "                                 expr(\"CASE WHEN implicit_feedback >= 0.5 THEN 1 ELSE 0 END\"))\n",
    "\n",
    "# Features\n",
    "feature_cols = [\"watch_time_seconds\", \"buffering_events\", \"skipped\", \"user_id_int\", \"video_id_int\"]\n",
    "\n",
    "# Change genre and region in indexes\n",
    "genre_indexer = StringIndexer(inputCol=\"genre\", outputCol=\"genre_index\")\n",
    "region_indexer = StringIndexer(inputCol=\"region\", outputCol=\"region_index\")\n",
    "\n",
    "# Assembler\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=feature_cols + [\"genre_index\", \"region_index\"],\n",
    "    outputCol=\"features\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8176623",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset\n",
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|    1|[1457.0,1.0,0.0,8...|\n",
      "|    1|[2824.0,2.0,0.0,6...|\n",
      "|    0|[468.0,2.0,0.0,64...|\n",
      "|    1|[1849.0,1.0,0.0,8...|\n",
      "|    1|[2954.0,2.0,0.0,6...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "Train set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1237:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|    0|[144.0,4.0,0.0,65...|\n",
      "|    0|[180.0,2.0,0.0,41...|\n",
      "|    0|[191.0,2.0,0.0,68...|\n",
      "|    0|[193.0,5.0,0.0,81...|\n",
      "|    0|[206.0,5.0,0.0,65...|\n",
      "|    0|[241.0,1.0,0.0,39...|\n",
      "|    0|[247.0,3.0,0.0,22...|\n",
      "|    0|[300.0,4.0,0.0,93...|\n",
      "|    0|[388.0,4.0,0.0,93...|\n",
      "|    0|[451.0,4.0,0.0,76...|\n",
      "|    0|[586.0,1.0,0.0,85...|\n",
      "|    0|[669.0,5.0,0.0,20...|\n",
      "|    0|[772.0,1.0,0.0,11...|\n",
      "|    0|[908.0,5.0,0.0,18...|\n",
      "|    0|[931.0,4.0,0.0,72...|\n",
      "|    0|[1239.0,4.0,0.0,5...|\n",
      "|    0|[1258.0,5.0,0.0,4...|\n",
      "|    0|[1292.0,4.0,0.0,1...|\n",
      "|    1|[890.0,0.0,0.0,71...|\n",
      "|    1|[1155.0,3.0,0.0,1...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Apply transformations\n",
    "data_label = genre_indexer.fit(video_data).transform(video_data)\n",
    "data_label = region_indexer.fit(data_label).transform(data_label)\n",
    "data_with_features = assembler.transform(data_label).select(\"label\", \"features\")\n",
    "\n",
    "# Divide data (train, test)\n",
    "train_df, test_df = data_with_features.randomSplit([0.7, 0.3], seed=57)\n",
    "\n",
    "print(\"Original Dataset\")\n",
    "data_with_features.show(5)\n",
    "\n",
    "print(\"\\nTrain set\")\n",
    "train_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1601f5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Tree model summary:DecisionTreeClassificationModel: uid=DecisionTreeClassifier_04b5643ad606, depth=3, numNodes=11, numClasses=2, numFeatures=7\n",
      "  If (feature 0 <= 826.5)\n",
      "   If (feature 0 <= 674.5)\n",
      "    Predict: 0.0\n",
      "   Else (feature 0 > 674.5)\n",
      "    If (feature 5 in {1.0,4.0})\n",
      "     Predict: 0.0\n",
      "    Else (feature 5 not in {1.0,4.0})\n",
      "     Predict: 1.0\n",
      "  Else (feature 0 > 826.5)\n",
      "   If (feature 0 <= 1338.5)\n",
      "    If (feature 1 <= 3.5)\n",
      "     Predict: 1.0\n",
      "    Else (feature 1 > 3.5)\n",
      "     Predict: 0.0\n",
      "   Else (feature 0 > 1338.5)\n",
      "    Predict: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "# Initialize and train the Decision Tree model\n",
    "dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "dt_model = dt.fit(train_df)\n",
    "\n",
    "# Display model summary\n",
    "print(\"\\nDecision Tree model summary:{0}\".format(dt_model.toDebugString))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a0bed238",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1252:============================>                           (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----------+\n",
      "|            features|label|prediction|\n",
      "+--------------------+-----+----------+\n",
      "|[268.0,2.0,0.0,85...|    0|       0.0|\n",
      "|[468.0,2.0,0.0,64...|    0|       0.0|\n",
      "|[1039.0,3.0,0.0,7...|    0|       1.0|\n",
      "|[1332.0,2.0,0.0,3...|    1|       1.0|\n",
      "|[1358.0,3.0,0.0,4...|    1|       1.0|\n",
      "|[1815.0,5.0,0.0,2...|    1|       1.0|\n",
      "|[2112.0,4.0,0.0,6...|    1|       1.0|\n",
      "|[2371.0,3.0,0.0,4...|    1|       1.0|\n",
      "|[2383.0,3.0,0.0,3...|    1|       1.0|\n",
      "|[139.0,3.0,0.0,33...|    0|       0.0|\n",
      "|[202.0,3.0,0.0,91...|    0|       0.0|\n",
      "|[481.0,2.0,0.0,80...|    0|       0.0|\n",
      "|[589.0,2.0,0.0,10...|    0|       0.0|\n",
      "|[994.0,0.0,0.0,28...|    1|       1.0|\n",
      "|[1453.0,4.0,0.0,4...|    1|       1.0|\n",
      "|[1821.0,1.0,0.0,2...|    1|       1.0|\n",
      "|[1879.0,3.0,0.0,9...|    1|       1.0|\n",
      "|[1885.0,0.0,0.0,6...|    1|       1.0|\n",
      "|[1902.0,0.0,0.0,9...|    1|       1.0|\n",
      "|[1989.0,4.0,0.0,9...|    1|       1.0|\n",
      "+--------------------+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = dt_model.transform(test_df)\n",
    "\n",
    "# Show predictions\n",
    "predictions.select(\"features\", \"label\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b9a4d97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9444444444444444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9484126984126984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.9444444444444444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1259:=====================================>                  (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9423868312757202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\",\n",
    "                            predictionCol=\"prediction\")\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions, \n",
    "                  {evaluator.metricName: \"accuracy\"})\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "precision = evaluator.evaluate(predictions,\n",
    "                  {evaluator.metricName: \"weightedPrecision\"})\n",
    "print(f\"Precision: {precision}\")\n",
    "recall = evaluator.evaluate(predictions,\n",
    "                  {evaluator.metricName: \"weightedRecall\"})\n",
    "print(f\"Recall: {recall}\")\n",
    "f1 = evaluator.evaluate(predictions,\n",
    "                {evaluator.metricName: \"f1\"})\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ea086ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----------+\n",
      "|            features|label|prediction|\n",
      "+--------------------+-----+----------+\n",
      "|[268.0,2.0,0.0,85...|    0|       0.0|\n",
      "|[468.0,2.0,0.0,64...|    0|       0.0|\n",
      "|[1039.0,3.0,0.0,7...|    0|       0.0|\n",
      "|[1332.0,2.0,0.0,3...|    1|       1.0|\n",
      "|[1358.0,3.0,0.0,4...|    1|       1.0|\n",
      "+--------------------+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy Score (OneVsRest + LinearSVC): 0.9722222222222222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score (OneVsRest + LinearSVC): 0.9747474747474747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score (OneVsRest + LinearSVC): 0.9722222222222222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1326:=====================================>                  (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score (OneVsRest + LinearSVC): 0.9726112667289137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LinearSVC, OneVsRest\n",
    "\n",
    "# LinearSVC\n",
    "lsvc = LinearSVC(maxIter=10, regParam=0.1, labelCol=\"label\", featuresCol=\"features\")\n",
    "\n",
    "# OneVsRest\n",
    "ovr = OneVsRest(classifier=lsvc, labelCol=\"label\", featuresCol=\"features\")\n",
    "\n",
    "# Train model\n",
    "ovr_model = ovr.fit(train_df)\n",
    "\n",
    "# Make predictions\n",
    "ovr_predictions = ovr_model.transform(test_df)\n",
    "\n",
    "# Show predictions\n",
    "ovr_predictions.select(\"features\", \"label\", \"prediction\").show(5)\n",
    "\n",
    "# Evaluate model\n",
    "accuracy_ovr = evaluator.evaluate(ovr_predictions, {evaluator.metricName: \"accuracy\"})\n",
    "print(f\"\\nAccuracy Score (OneVsRest + LinearSVC): {accuracy_ovr}\")\n",
    "\n",
    "precision_ovr = evaluator.evaluate(ovr_predictions, {evaluator.metricName: \"weightedPrecision\"})\n",
    "print(f\"Precision Score (OneVsRest + LinearSVC): {precision_ovr}\")\n",
    "\n",
    "recall_ovr = evaluator.evaluate(ovr_predictions, {evaluator.metricName: \"weightedRecall\"})\n",
    "print(f\"Recall Score (OneVsRest + LinearSVC): {recall_ovr}\")\n",
    "\n",
    "f1_ovr = evaluator.evaluate(ovr_predictions, {evaluator.metricName: \"f1\"})\n",
    "print(f\"F1 Score (OneVsRest + LinearSVC): {f1_ovr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dde535e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc56a6a3",
   "metadata": {},
   "source": [
    "# 6. Conclusion\n",
    "\n",
    "## Main Achievements\n",
    "- Real-time recommendation system operational\n",
    "- Scalable data pipeline\n",
    "- Model with good accuracy metrics\n",
    "\n",
    "## Key Learnings\n",
    "1. Importance of preprocessing for streaming data\n",
    "2. Advantages of ALS for implicit feedback\n",
    "3. Challenges in the balance between coverage and diversity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
